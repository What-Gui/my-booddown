<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Computational Security | A Minimal Book Example</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Computational Security | A Minimal Book Example" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Computational Security | A Minimal Book Example" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="pseudorandomness.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="mathematical-background.html"><a href="mathematical-background.html"><i class="fa fa-check"></i><b>1</b> Mathematical Background</a>
<ul>
<li class="chapter" data-level="1.1" data-path="mathematical-background.html"><a href="mathematical-background.html#a-quick-overview-of-mathematical-prerequisites"><i class="fa fa-check"></i><b>1.1</b> A quick overview of mathematical prerequisites</a></li>
<li class="chapter" data-level="1.2" data-path="mathematical-background.html"><a href="mathematical-background.html#mathematical-proofs"><i class="fa fa-check"></i><b>1.2</b> Mathematical Proofs</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="mathematical-background.html"><a href="mathematical-background.html#example-the-existence-of-infinitely-many-primes."><i class="fa fa-check"></i><b>1.2.1</b> Example: The existence of infinitely many primes.</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="mathematical-background.html"><a href="mathematical-background.html#probability-and-sample-spaces"><i class="fa fa-check"></i><b>1.3</b> Probability and Sample spaces</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="mathematical-background.html"><a href="mathematical-background.html#random-variables"><i class="fa fa-check"></i><b>1.3.1</b> Random variables</a></li>
<li class="chapter" data-level="1.3.2" data-path="mathematical-background.html"><a href="mathematical-background.html#distributions-over-strings"><i class="fa fa-check"></i><b>1.3.2</b> Distributions over strings</a></li>
<li class="chapter" data-level="1.3.3" data-path="mathematical-background.html"><a href="mathematical-background.html#more-general-sample-spaces."><i class="fa fa-check"></i><b>1.3.3</b> More general sample spaces.</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="mathematical-background.html"><a href="mathematical-background.html#correlations-and-independence"><i class="fa fa-check"></i><b>1.4</b> Correlations and independence</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="mathematical-background.html"><a href="mathematical-background.html#independent-random-variables"><i class="fa fa-check"></i><b>1.4.1</b> Independent random variables</a></li>
<li class="chapter" data-level="1.4.2" data-path="mathematical-background.html"><a href="mathematical-background.html#collections-of-independent-random-variables."><i class="fa fa-check"></i><b>1.4.2</b> Collections of independent random variables.</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="mathematical-background.html"><a href="mathematical-background.html#concentration-and-tail-bounds"><i class="fa fa-check"></i><b>1.5</b> Concentration and tail bounds</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="mathematical-background.html"><a href="mathematical-background.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>1.5.1</b> Chebyshev’s Inequality</a></li>
<li class="chapter" data-level="1.5.2" data-path="mathematical-background.html"><a href="mathematical-background.html#the-chernoff-bound"><i class="fa fa-check"></i><b>1.5.2</b> The Chernoff bound</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="mathematical-background.html"><a href="mathematical-background.html#exercises"><i class="fa fa-check"></i><b>1.6</b> Exercises</a></li>
<li class="chapter" data-level="1.7" data-path="mathematical-background.html"><a href="mathematical-background.html#exercises-1"><i class="fa fa-check"></i><b>1.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#some-history"><i class="fa fa-check"></i><b>2.1</b> Some history</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#defining-encryptions"><i class="fa fa-check"></i><b>2.2</b> Defining encryptions</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#defining-security-of-encryption"><i class="fa fa-check"></i><b>2.3</b> Defining security of encryption</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction.html"><a href="introduction.html#generating-randomness-in-actual-cryptographic-systems"><i class="fa fa-check"></i><b>2.3.1</b> Generating randomness in actual cryptographic systems</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#defining-the-secrecy-requirement."><i class="fa fa-check"></i><b>2.4</b> Defining the secrecy requirement.</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#perfect-secrecy"><i class="fa fa-check"></i><b>2.5</b> Perfect Secrecy</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#achieving-perfect-secrecy"><i class="fa fa-check"></i><b>2.5.1</b> Achieving perfect secrecy</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#necessity-of-long-keys"><i class="fa fa-check"></i><b>2.6</b> Necessity of long keys</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="introduction.html"><a href="introduction.html#amplifying-success-probability"><i class="fa fa-check"></i><b>2.6.1</b> Amplifying success probability</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="introduction.html"><a href="introduction.html#bibliographical-notes"><i class="fa fa-check"></i><b>2.7</b> Bibliographical notes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="computational-security.html"><a href="computational-security.html"><i class="fa fa-check"></i><b>3</b> Computational Security</a>
<ul>
<li class="chapter" data-level="3.0.1" data-path="computational-security.html"><a href="computational-security.html#proof-by-reduction"><i class="fa fa-check"></i><b>3.0.1</b> Proof by reduction</a></li>
<li class="chapter" data-level="3.1" data-path="computational-security.html"><a href="computational-security.html#the-asymptotic-approach"><i class="fa fa-check"></i><b>3.1</b> The asymptotic approach</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="computational-security.html"><a href="computational-security.html#countoperation"><i class="fa fa-check"></i><b>3.1.1</b> Counting number of operations.</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="computational-security.html"><a href="computational-security.html#our-first-conjecture"><i class="fa fa-check"></i><b>3.2</b> Our first conjecture</a></li>
<li class="chapter" data-level="3.3" data-path="computational-security.html"><a href="computational-security.html#why-care-about-the-cipher-conjecture"><i class="fa fa-check"></i><b>3.3</b> Why care about the cipher conjecture?</a></li>
<li class="chapter" data-level="3.4" data-path="computational-security.html"><a href="computational-security.html#prelude-computational-indistinguishability"><i class="fa fa-check"></i><b>3.4</b> Prelude: Computational Indistinguishability</a></li>
<li class="chapter" data-level="3.5" data-path="computational-security.html"><a href="computational-security.html#the-length-extension-theorem-or-stream-ciphers"><i class="fa fa-check"></i><b>3.5</b> The Length Extension Theorem or Stream Ciphers</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="computational-security.html"><a href="computational-security.html#appendix-the-computational-model"><i class="fa fa-check"></i><b>3.5.1</b> Appendix: The computational model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="pseudorandomness.html"><a href="pseudorandomness.html"><i class="fa fa-check"></i><b>4</b> Pseudorandomness</a>
<ul>
<li class="chapter" data-level="4.0.1" data-path="pseudorandomness.html"><a href="pseudorandomness.html#unpredictability-an-alternative-approach-for-proving-the-length-extension-theorem"><i class="fa fa-check"></i><b>4.0.1</b> Unpredictability: an alternative approach for proving the length extension theorem</a></li>
<li class="chapter" data-level="4.1" data-path="pseudorandomness.html"><a href="pseudorandomness.html#stream-ciphers"><i class="fa fa-check"></i><b>4.1</b> Stream ciphers</a></li>
<li class="chapter" data-level="4.2" data-path="pseudorandomness.html"><a href="pseudorandomness.html#what-do-pseudorandom-generators-actually-look-like"><i class="fa fa-check"></i><b>4.2</b> What do pseudorandom generators actually look like?</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="pseudorandomness.html"><a href="pseudorandomness.html#attempt-0-the-counter-generator"><i class="fa fa-check"></i><b>4.2.1</b> Attempt 0: The counter generator</a></li>
<li class="chapter" data-level="4.2.2" data-path="pseudorandomness.html"><a href="pseudorandomness.html#attempt-1-the-linear-checksum-linear-feedback-shift-register-lfsr"><i class="fa fa-check"></i><b>4.2.2</b> Attempt 1: The linear checksum / linear feedback shift register (LFSR)</a></li>
<li class="chapter" data-level="4.2.3" data-path="pseudorandomness.html"><a href="pseudorandomness.html#from-insecurity-to-security"><i class="fa fa-check"></i><b>4.2.3</b> From insecurity to security</a></li>
<li class="chapter" data-level="4.2.4" data-path="pseudorandomness.html"><a href="pseudorandomness.html#attempt-2-linear-congruential-generators-with-dropped-bits"><i class="fa fa-check"></i><b>4.2.4</b> Attempt 2: Linear Congruential Generators with dropped bits</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="pseudorandomness.html"><a href="pseudorandomness.html#successful-examples"><i class="fa fa-check"></i><b>4.3</b> Successful examples</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="pseudorandomness.html"><a href="pseudorandomness.html#case-study-1-subset-sum-generator"><i class="fa fa-check"></i><b>4.3.1</b> Case Study 1: Subset Sum Generator</a></li>
<li class="chapter" data-level="4.3.2" data-path="pseudorandomness.html"><a href="pseudorandomness.html#case-study-2-rc4"><i class="fa fa-check"></i><b>4.3.2</b> Case Study 2: RC4</a></li>
<li class="chapter" data-level="4.3.3" data-path="pseudorandomness.html"><a href="pseudorandomness.html#case-study-3-blum-blum-and-shub"><i class="fa fa-check"></i><b>4.3.3</b> Case Study 3: Blum, Blum and Shub</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="pseudorandomness.html"><a href="pseudorandomness.html#non-constructive-existence-of-pseudorandom-generators"><i class="fa fa-check"></i><b>4.4</b> Non-constructive existence of pseudorandom generators</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="pseudorandom-functions.html"><a href="pseudorandom-functions.html"><i class="fa fa-check"></i><b>5</b> Pseudorandom functions</a>
<ul>
<li class="chapter" data-level="5.1" data-path="pseudorandom-functions.html"><a href="pseudorandom-functions.html#one-time-passwords-e.g.-google-authenticator-rsa-id-etc."><i class="fa fa-check"></i><b>5.1</b> One time passwords (e.g. Google Authenticator, RSA ID, etc.)</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="pseudorandom-functions.html"><a href="pseudorandom-functions.html#how-do-pseudorandom-functions-help-in-the-login-problem"><i class="fa fa-check"></i><b>5.1.1</b> How do pseudorandom functions help in the login problem?</a></li>
<li class="chapter" data-level="5.1.2" data-path="pseudorandom-functions.html"><a href="pseudorandom-functions.html#modifying-input-and-output-lengths-of-prfs"><i class="fa fa-check"></i><b>5.1.2</b> Modifying input and output lengths of PRFs</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="pseudorandom-functions.html"><a href="pseudorandom-functions.html#message-authentication-codes"><i class="fa fa-check"></i><b>5.2</b> Message Authentication Codes</a></li>
<li class="chapter" data-level="5.3" data-path="pseudorandom-functions.html"><a href="pseudorandom-functions.html#macs-from-prfs"><i class="fa fa-check"></i><b>5.3</b> MACs from PRFs</a></li>
<li class="chapter" data-level="5.4" data-path="pseudorandom-functions.html"><a href="pseudorandom-functions.html#arbitrary-input-length-extension-for-macs-and-prfs"><i class="fa fa-check"></i><b>5.4</b> Arbitrary input length extension for MACs and PRFs</a></li>
<li class="chapter" data-level="5.5" data-path="pseudorandom-functions.html"><a href="pseudorandom-functions.html#aside-natural-proofs"><i class="fa fa-check"></i><b>5.5</b> Aside: natural proofs</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="pseudorandom-functions-from-pseudorandom-generators-and-cpa-security.html"><a href="pseudorandom-functions-from-pseudorandom-generators-and-cpa-security.html"><i class="fa fa-check"></i><b>6</b> Pseudorandom functions from pseudorandom generators and CPA security</a>
<ul>
<li class="chapter" data-level="6.1" data-path="pseudorandom-functions-from-pseudorandom-generators-and-cpa-security.html"><a href="pseudorandom-functions-from-pseudorandom-generators-and-cpa-security.html#securely-encrypting-many-messages---chosen-plaintext-security"><i class="fa fa-check"></i><b>6.1</b> Securely encrypting many messages - chosen plaintext security</a></li>
<li class="chapter" data-level="6.2" data-path="pseudorandom-functions-from-pseudorandom-generators-and-cpa-security.html"><a href="pseudorandom-functions-from-pseudorandom-generators-and-cpa-security.html#pseudorandom-permutations-block-ciphers"><i class="fa fa-check"></i><b>6.2</b> Pseudorandom permutations / block ciphers</a></li>
<li class="chapter" data-level="6.3" data-path="pseudorandom-functions-from-pseudorandom-generators-and-cpa-security.html"><a href="pseudorandom-functions-from-pseudorandom-generators-and-cpa-security.html#encryption-modes"><i class="fa fa-check"></i><b>6.3</b> Encryption modes</a></li>
<li class="chapter" data-level="6.4" data-path="pseudorandom-functions-from-pseudorandom-generators-and-cpa-security.html"><a href="pseudorandom-functions-from-pseudorandom-generators-and-cpa-security.html#optional-aside-broadcast-encryption"><i class="fa fa-check"></i><b>6.4</b> Optional, Aside: Broadcast Encryption</a></li>
<li class="chapter" data-level="6.5" data-path="pseudorandom-functions-from-pseudorandom-generators-and-cpa-security.html"><a href="pseudorandom-functions-from-pseudorandom-generators-and-cpa-security.html#reading-comprehension-exercises"><i class="fa fa-check"></i><b>6.5</b> Reading comprehension exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chosen-ciphertext-security.html"><a href="chosen-ciphertext-security.html"><i class="fa fa-check"></i><b>7</b> Chosen Ciphertext Security</a>
<ul>
<li class="chapter" data-level="7.1" data-path="chosen-ciphertext-security.html"><a href="chosen-ciphertext-security.html#short-recap"><i class="fa fa-check"></i><b>7.1</b> Short recap</a></li>
<li class="chapter" data-level="7.2" data-path="chosen-ciphertext-security.html"><a href="chosen-ciphertext-security.html#going-beyond-cpa"><i class="fa fa-check"></i><b>7.2</b> Going beyond CPA</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="chosen-ciphertext-security.html"><a href="chosen-ciphertext-security.html#example-the-wired-equivalence-privacy-wep"><i class="fa fa-check"></i><b>7.2.1</b> Example: The Wired Equivalence Privacy (WEP)</a></li>
<li class="chapter" data-level="7.2.2" data-path="chosen-ciphertext-security.html"><a href="chosen-ciphertext-security.html#chosen-ciphertext-security-1"><i class="fa fa-check"></i><b>7.2.2</b> Chosen ciphertext security</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="chosen-ciphertext-security.html"><a href="chosen-ciphertext-security.html#constructing-cca-secure-encryption"><i class="fa fa-check"></i><b>7.3</b> Constructing CCA secure encryption</a></li>
<li class="chapter" data-level="7.4" data-path="chosen-ciphertext-security.html"><a href="chosen-ciphertext-security.html#simplified-gcm-encryption"><i class="fa fa-check"></i><b>7.4</b> (Simplified) GCM encryption</a></li>
<li class="chapter" data-level="7.5" data-path="chosen-ciphertext-security.html"><a href="chosen-ciphertext-security.html#padding-chopping-and-their-pitfalls-the-buffer-overflow-of-cryptography"><i class="fa fa-check"></i><b>7.5</b> Padding, chopping, and their pitfalls: the “buffer overflow” of cryptography</a></li>
<li class="chapter" data-level="7.6" data-path="chosen-ciphertext-security.html"><a href="chosen-ciphertext-security.html#chosen-ciphertext-attack-as-implementing-metaphors"><i class="fa fa-check"></i><b>7.6</b> Chosen ciphertext attack as implementing metaphors</a></li>
<li class="chapter" data-level="7.7" data-path="chosen-ciphertext-security.html"><a href="chosen-ciphertext-security.html#reading-comprehension-exercises-1"><i class="fa fa-check"></i><b>7.7</b> Reading comprehension exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hash-functions-random-oracles-and-bitcoin.html"><a href="hash-functions-random-oracles-and-bitcoin.html"><i class="fa fa-check"></i><b>8</b> Hash Functions, Random Oracles, and Bitcoin</a></li>
<li class="chapter" data-level="9" data-path="key-derivation-protecting-passwords-slow-hashes-merkle-trees.html"><a href="key-derivation-protecting-passwords-slow-hashes-merkle-trees.html"><i class="fa fa-check"></i><b>9</b> Key derivation, protecting passwords, slow hashes, Merkle trees</a>
<ul>
<li class="chapter" data-level="9.1" data-path="key-derivation-protecting-passwords-slow-hashes-merkle-trees.html"><a href="key-derivation-protecting-passwords-slow-hashes-merkle-trees.html#keys-from-passwords"><i class="fa fa-check"></i><b>9.1</b> Keys from passwords</a></li>
<li class="chapter" data-level="9.2" data-path="key-derivation-protecting-passwords-slow-hashes-merkle-trees.html"><a href="key-derivation-protecting-passwords-slow-hashes-merkle-trees.html#merkle-trees-and-verifying-storage."><i class="fa fa-check"></i><b>9.2</b> Merkle trees and verifying storage.</a></li>
<li class="chapter" data-level="9.3" data-path="key-derivation-protecting-passwords-slow-hashes-merkle-trees.html"><a href="key-derivation-protecting-passwords-slow-hashes-merkle-trees.html#proofs-of-retrievability"><i class="fa fa-check"></i><b>9.3</b> Proofs of Retrievability</a></li>
<li class="chapter" data-level="9.4" data-path="key-derivation-protecting-passwords-slow-hashes-merkle-trees.html"><a href="key-derivation-protecting-passwords-slow-hashes-merkle-trees.html#entropy-extraction"><i class="fa fa-check"></i><b>9.4</b> Entropy extraction</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="key-derivation-protecting-passwords-slow-hashes-merkle-trees.html"><a href="key-derivation-protecting-passwords-slow-hashes-merkle-trees.html#forward-and-backward-secrecy"><i class="fa fa-check"></i><b>9.4.1</b> Forward and backward secrecy</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html"><i class="fa fa-check"></i><b>10</b> Public key cryptography</a>
<ul>
<li class="chapter" data-level="10.1" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#private-key-crypto-recap"><i class="fa fa-check"></i><b>10.1</b> Private key crypto recap</a></li>
<li class="chapter" data-level="10.2" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#public-key-encryptions-definition"><i class="fa fa-check"></i><b>10.2</b> Public Key Encryptions: Definition</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#the-obfuscation-paradigm"><i class="fa fa-check"></i><b>10.2.1</b> The obfuscation paradigm</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#some-concrete-candidates"><i class="fa fa-check"></i><b>10.3</b> Some concrete candidates:</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#diffie-hellman-encryption-aka-el-gamal"><i class="fa fa-check"></i><b>10.3.1</b> Diffie-Hellman Encryption (aka El-Gamal)</a></li>
<li class="chapter" data-level="10.3.2" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#sampling-random-primes"><i class="fa fa-check"></i><b>10.3.2</b> Sampling random primes</a></li>
<li class="chapter" data-level="10.3.3" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#a-little-bit-of-group-theory."><i class="fa fa-check"></i><b>10.3.3</b> A little bit of group theory.</a></li>
<li class="chapter" data-level="10.3.4" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#digital-signatures"><i class="fa fa-check"></i><b>10.3.4</b> Digital Signatures</a></li>
<li class="chapter" data-level="10.3.5" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#the-digital-signature-algorithm-dsa"><i class="fa fa-check"></i><b>10.3.5</b> The Digital Signature Algorithm (DSA)</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#putting-everything-together---security-in-practice."><i class="fa fa-check"></i><b>10.4</b> Putting everything together - security in practice.</a></li>
<li class="chapter" data-level="10.5" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#appendix-an-alternative-proof-of-the-density-of-primes"><i class="fa fa-check"></i><b>10.5</b> Appendix: An alternative proof of the density of primes</a></li>
<li class="chapter" data-level="10.6" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#additional-group-theory-exercises-and-proofs"><i class="fa fa-check"></i><b>10.6</b> Additional Group Theory Exercises and Proofs</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="public-key-cryptography.html"><a href="public-key-cryptography.html#solved-exercises"><i class="fa fa-check"></i><b>10.6.1</b> Solved exercises:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="concrete-candidates-for-public-key-crypto.html"><a href="concrete-candidates-for-public-key-crypto.html"><i class="fa fa-check"></i><b>11</b> Concrete candidates for public key crypto</a>
<ul>
<li class="chapter" data-level="11.1" data-path="concrete-candidates-for-public-key-crypto.html"><a href="concrete-candidates-for-public-key-crypto.html#some-number-theory."><i class="fa fa-check"></i><b>11.1</b> Some number theory.</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="concrete-candidates-for-public-key-crypto.html"><a href="concrete-candidates-for-public-key-crypto.html#primaliy-testing"><i class="fa fa-check"></i><b>11.1.1</b> Primaliy testing</a></li>
<li class="chapter" data-level="11.1.2" data-path="concrete-candidates-for-public-key-crypto.html"><a href="concrete-candidates-for-public-key-crypto.html#fields"><i class="fa fa-check"></i><b>11.1.2</b> Fields</a></li>
<li class="chapter" data-level="11.1.3" data-path="concrete-candidates-for-public-key-crypto.html"><a href="concrete-candidates-for-public-key-crypto.html#chinese-remainder-theorem"><i class="fa fa-check"></i><b>11.1.3</b> Chinese remainder theorem</a></li>
<li class="chapter" data-level="11.1.4" data-path="concrete-candidates-for-public-key-crypto.html"><a href="concrete-candidates-for-public-key-crypto.html#the-rsa-and-rabin-functions"><i class="fa fa-check"></i><b>11.1.4</b> The RSA and Rabin functions</a></li>
<li class="chapter" data-level="11.1.5" data-path="concrete-candidates-for-public-key-crypto.html"><a href="concrete-candidates-for-public-key-crypto.html#abstraction-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.5</b> Abstraction: trapdoor permutations</a></li>
<li class="chapter" data-level="11.1.6" data-path="concrete-candidates-for-public-key-crypto.html"><a href="concrete-candidates-for-public-key-crypto.html#public-key-encryption-from-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.6</b> Public key encryption from trapdoor permutations</a></li>
<li class="chapter" data-level="11.1.7" data-path="concrete-candidates-for-public-key-crypto.html"><a href="concrete-candidates-for-public-key-crypto.html#digital-signatures-from-trapdoor-permutations"><i class="fa fa-check"></i><b>11.1.7</b> Digital signatures from trapdoor permutations</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="concrete-candidates-for-public-key-crypto.html"><a href="concrete-candidates-for-public-key-crypto.html#hardcore-bits-and-security-without-random-oracles"><i class="fa fa-check"></i><b>11.2</b> Hardcore bits and security without random oracles</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="concrete-candidates-for-public-key-crypto.html"><a href="concrete-candidates-for-public-key-crypto.html#extending-to-more-than-one-hardcore-bit"><i class="fa fa-check"></i><b>11.2.1</b> Extending to more than one hardcore bit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="lattice-based-cryptography.html"><a href="lattice-based-cryptography.html"><i class="fa fa-check"></i><b>12</b> Lattice based cryptography</a>
<ul>
<li class="chapter" data-level="12.0.1" data-path="lattice-based-cryptography.html"><a href="lattice-based-cryptography.html#quick-linear-algebra-recap"><i class="fa fa-check"></i><b>12.0.1</b> Quick linear algebra recap</a></li>
<li class="chapter" data-level="12.1" data-path="lattice-based-cryptography.html"><a href="lattice-based-cryptography.html#a-world-without-gaussian-elimination"><i class="fa fa-check"></i><b>12.1</b> A world without Gaussian elimination</a></li>
<li class="chapter" data-level="12.2" data-path="lattice-based-cryptography.html"><a href="lattice-based-cryptography.html#security-in-the-real-world."><i class="fa fa-check"></i><b>12.2</b> Security in the real world.</a></li>
<li class="chapter" data-level="12.3" data-path="lattice-based-cryptography.html"><a href="lattice-based-cryptography.html#search-to-decision"><i class="fa fa-check"></i><b>12.3</b> Search to decision</a></li>
<li class="chapter" data-level="12.4" data-path="lattice-based-cryptography.html"><a href="lattice-based-cryptography.html#lweencsec"><i class="fa fa-check"></i><b>12.4</b> An LWE based encryption scheme</a></li>
<li class="chapter" data-level="12.5" data-path="lattice-based-cryptography.html"><a href="lattice-based-cryptography.html#but-what-are-lattices"><i class="fa fa-check"></i><b>12.5</b> But what are lattices?</a></li>
<li class="chapter" data-level="12.6" data-path="lattice-based-cryptography.html"><a href="lattice-based-cryptography.html#ring-based-lattices"><i class="fa fa-check"></i><b>12.6</b> Ring based lattices</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="establishing-secure-connections-over-insecure-channels.html"><a href="establishing-secure-connections-over-insecure-channels.html"><i class="fa fa-check"></i><b>13</b> Establishing secure connections over insecure channels</a>
<ul>
<li class="chapter" data-level="13.1" data-path="establishing-secure-connections-over-insecure-channels.html"><a href="establishing-secure-connections-over-insecure-channels.html#cryptographys-obsession-with-adjectives."><i class="fa fa-check"></i><b>13.1</b> Cryptography’s obsession with adjectives.</a></li>
<li class="chapter" data-level="13.2" data-path="establishing-secure-connections-over-insecure-channels.html"><a href="establishing-secure-connections-over-insecure-channels.html#basic-key-exchange-protocol"><i class="fa fa-check"></i><b>13.2</b> Basic Key Exchange protocol</a></li>
<li class="chapter" data-level="13.3" data-path="establishing-secure-connections-over-insecure-channels.html"><a href="establishing-secure-connections-over-insecure-channels.html#authenticated-key-exchange"><i class="fa fa-check"></i><b>13.3</b> Authenticated key exchange</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="establishing-secure-connections-over-insecure-channels.html"><a href="establishing-secure-connections-over-insecure-channels.html#bleichenbachers-attack-on-rsa-pkcs-v1.5-and-ssl-v3.0"><i class="fa fa-check"></i><b>13.3.1</b> Bleichenbacher’s attack on RSA PKCS V1.5 and SSL V3.0</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="establishing-secure-connections-over-insecure-channels.html"><a href="establishing-secure-connections-over-insecure-channels.html#chosen-ciphertext-attack-security-for-public-key-cryptography"><i class="fa fa-check"></i><b>13.4</b> Chosen ciphertext attack security for public key cryptography</a></li>
<li class="chapter" data-level="13.5" data-path="establishing-secure-connections-over-insecure-channels.html"><a href="establishing-secure-connections-over-insecure-channels.html#cca-secure-public-key-encryption-in-the-random-oracle-model"><i class="fa fa-check"></i><b>13.5</b> CCA secure public key encryption in the Random Oracle Model</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="establishing-secure-connections-over-insecure-channels.html"><a href="establishing-secure-connections-over-insecure-channels.html#defining-secure-authenticated-key-exchange"><i class="fa fa-check"></i><b>13.5.1</b> Defining secure authenticated key exchange</a></li>
<li class="chapter" data-level="13.5.2" data-path="establishing-secure-connections-over-insecure-channels.html"><a href="establishing-secure-connections-over-insecure-channels.html#the-compiler-approach-for-authenticated-key-exchange"><i class="fa fa-check"></i><b>13.5.2</b> The compiler approach for authenticated key exchange</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="establishing-secure-connections-over-insecure-channels.html"><a href="establishing-secure-connections-over-insecure-channels.html#password-authenticated-key-exchange."><i class="fa fa-check"></i><b>13.6</b> Password authenticated key exchange.</a></li>
<li class="chapter" data-level="13.7" data-path="establishing-secure-connections-over-insecure-channels.html"><a href="establishing-secure-connections-over-insecure-channels.html#client-to-client-key-exchange-for-secure-text-messaging---zrtp-otr-textsecure"><i class="fa fa-check"></i><b>13.7</b> Client to client key exchange for secure text messaging - ZRTP, OTR, TextSecure</a></li>
<li class="chapter" data-level="13.8" data-path="establishing-secure-connections-over-insecure-channels.html"><a href="establishing-secure-connections-over-insecure-channels.html#heartbleed-and-logjam-attacks"><i class="fa fa-check"></i><b>13.8</b> Heartbleed and logjam attacks</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="zero-knowledge-proofs.html"><a href="zero-knowledge-proofs.html"><i class="fa fa-check"></i><b>14</b> Zero knowledge proofs</a>
<ul>
<li class="chapter" data-level="14.1" data-path="zero-knowledge-proofs.html"><a href="zero-knowledge-proofs.html#applications-for-zero-knowledge-proofs."><i class="fa fa-check"></i><b>14.1</b> Applications for zero knowledge proofs.</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="zero-knowledge-proofs.html"><a href="zero-knowledge-proofs.html#nuclear-disarmament"><i class="fa fa-check"></i><b>14.1.1</b> Nuclear disarmament</a></li>
<li class="chapter" data-level="14.1.2" data-path="zero-knowledge-proofs.html"><a href="zero-knowledge-proofs.html#voting"><i class="fa fa-check"></i><b>14.1.2</b> Voting</a></li>
<li class="chapter" data-level="14.1.3" data-path="zero-knowledge-proofs.html"><a href="zero-knowledge-proofs.html#more-applications"><i class="fa fa-check"></i><b>14.1.3</b> More applications</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="zero-knowledge-proofs.html"><a href="zero-knowledge-proofs.html#defining-and-constructing-zero-knowledge-proofs"><i class="fa fa-check"></i><b>14.2</b> Defining and constructing zero knowledge proofs</a></li>
<li class="chapter" data-level="14.3" data-path="zero-knowledge-proofs.html"><a href="zero-knowledge-proofs.html#defining-zero-knowledge"><i class="fa fa-check"></i><b>14.3</b> Defining zero knowledge</a></li>
<li class="chapter" data-level="14.4" data-path="zero-knowledge-proofs.html"><a href="zero-knowledge-proofs.html#zero-knowledge-proof-for-hamiltonicity."><i class="fa fa-check"></i><b>14.4</b> Zero knowledge proof for Hamiltonicity.</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="zero-knowledge-proofs.html"><a href="zero-knowledge-proofs.html#why-is-this-interesting"><i class="fa fa-check"></i><b>14.4.1</b> Why is this interesting?</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="zero-knowledge-proofs.html"><a href="zero-knowledge-proofs.html#parallel-repetition-and-turning-zero-knowledge-proofs-to-signatures."><i class="fa fa-check"></i><b>14.5</b> Parallel repetition and turning zero knowledge proofs to signatures.</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="zero-knowledge-proofs.html"><a href="zero-knowledge-proofs.html#bonus-features-of-zero-knowledge"><i class="fa fa-check"></i><b>14.5.1</b> “Bonus features” of zero knowledge</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="chapfheone.html"><a href="chapfheone.html"><i class="fa fa-check"></i><b>15</b> Fully homomorphic encryption: Introduction and bootstrapping</a>
<ul>
<li class="chapter" data-level="15.1" data-path="chapfheone.html"><a href="chapfheone.html#defining-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>15.1</b> Defining fully homomorphic encryption</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="chapfheone.html"><a href="chapfheone.html#another-application-fully-homomorphic-encryption-for-verifying-computation"><i class="fa fa-check"></i><b>15.1.1</b> Another application: fully homomorphic encryption for verifying computation</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="chapfheone.html"><a href="chapfheone.html#example-an-xor-homomorphic-encryption"><i class="fa fa-check"></i><b>15.2</b> Example: An XOR homomorphic encryption</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="chapfheone.html"><a href="chapfheone.html#abstraction-a-trapdoor-pseudorandom-generator."><i class="fa fa-check"></i><b>15.2.1</b> Abstraction: A trapdoor pseudorandom generator.</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="chapfheone.html"><a href="chapfheone.html#from-linear-homomorphism-to-full-homomorphism"><i class="fa fa-check"></i><b>15.3</b> From linear homomorphism to full homomorphism</a></li>
<li class="chapter" data-level="15.4" data-path="chapfheone.html"><a href="chapfheone.html#bootstrapping-fully-homomorphic-escape-velocity"><i class="fa fa-check"></i><b>15.4</b> Bootstrapping: Fully Homomorphic “escape velocity”</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="chapfheone.html"><a href="chapfheone.html#radioactive-legos-analogy"><i class="fa fa-check"></i><b>15.4.1</b> Radioactive legos analogy</a></li>
<li class="chapter" data-level="15.4.2" data-path="chapfheone.html"><a href="chapfheone.html#proving-the-bootstrapping-theorem"><i class="fa fa-check"></i><b>15.4.2</b> Proving the bootstrapping theorem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="chapfhetwo.html"><a href="chapfhetwo.html"><i class="fa fa-check"></i><b>16</b> Fully homomorphic encryption: Construction</a>
<ul>
<li class="chapter" data-level="16.1" data-path="chapfhetwo.html"><a href="chapfhetwo.html#prelude-from-vectors-to-matrices"><i class="fa fa-check"></i><b>16.1</b> Prelude: from vectors to matrices</a></li>
<li class="chapter" data-level="16.2" data-path="chapfhetwo.html"><a href="chapfhetwo.html#real-world-partially-homomorphic-encryption"><i class="fa fa-check"></i><b>16.2</b> Real world partially homomorphic encryption</a></li>
<li class="chapter" data-level="16.3" data-path="chapfhetwo.html"><a href="chapfhetwo.html#noise-management-via-encoding"><i class="fa fa-check"></i><b>16.3</b> Noise management via encoding</a></li>
<li class="chapter" data-level="16.4" data-path="chapfhetwo.html"><a href="chapfhetwo.html#putting-it-all-together"><i class="fa fa-check"></i><b>16.4</b> Putting it all together</a></li>
<li class="chapter" data-level="16.5" data-path="chapfhetwo.html"><a href="chapfhetwo.html#analysis-of-our-scheme"><i class="fa fa-check"></i><b>16.5</b> Analysis of our scheme</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="chapfhetwo.html"><a href="chapfhetwo.html#correctness"><i class="fa fa-check"></i><b>16.5.1</b> Correctness</a></li>
<li class="chapter" data-level="16.5.2" data-path="chapfhetwo.html"><a href="chapfhetwo.html#cpa-security"><i class="fa fa-check"></i><b>16.5.2</b> CPA Security</a></li>
<li class="chapter" data-level="16.5.3" data-path="chapfhetwo.html"><a href="chapfhetwo.html#homomorphism"><i class="fa fa-check"></i><b>16.5.3</b> Homomorphism</a></li>
<li class="chapter" data-level="16.5.4" data-path="chapfhetwo.html"><a href="chapfhetwo.html#shallow-decryption-circuit"><i class="fa fa-check"></i><b>16.5.4</b> Shallow decryption circuit</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="chapfhetwo.html"><a href="chapfhetwo.html#advanced-topics"><i class="fa fa-check"></i><b>16.6</b> Advanced topics:</a>
<ul>
<li class="chapter" data-level="16.6.1" data-path="chapfhetwo.html"><a href="chapfhetwo.html#fully-homomorphic-encryption-for-approximate-computation-over-the-real-numbers-ckks"><i class="fa fa-check"></i><b>16.6.1</b> Fully homomorphic encryption for approximate computation over the real numbers: CKKS</a></li>
<li class="chapter" data-level="16.6.2" data-path="chapfhetwo.html"><a href="chapfhetwo.html#bandwidth-efficient-fully-homomorphic-encryption-gh"><i class="fa fa-check"></i><b>16.6.2</b> Bandwidth efficient fully homomorphic encryption GH</a></li>
<li class="chapter" data-level="16.6.3" data-path="chapfhetwo.html"><a href="chapfhetwo.html#using-fully-homomorphic-encryption-to-achieve-private-information-retrieval."><i class="fa fa-check"></i><b>16.6.3</b> Using fully homomorphic encryption to achieve private information retrieval.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="sfeonechap.html"><a href="sfeonechap.html"><i class="fa fa-check"></i><b>17</b> Multiparty secure computation I: Definition and Honest-But-Curious to Malicious complier</a>
<ul>
<li class="chapter" data-level="17.1" data-path="sfeonechap.html"><a href="sfeonechap.html#ideal-vs.-real-model-security."><i class="fa fa-check"></i><b>17.1</b> Ideal vs. Real Model Security.</a></li>
<li class="chapter" data-level="17.2" data-path="sfeonechap.html"><a href="sfeonechap.html#formally-defining-secure-multiparty-computation"><i class="fa fa-check"></i><b>17.2</b> Formally defining secure multiparty computation</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="sfeonechap.html"><a href="sfeonechap.html#first-attempt-a-slightly-too-ideal-definition"><i class="fa fa-check"></i><b>17.2.1</b> First attempt: a slightly “too ideal” definition</a></li>
<li class="chapter" data-level="17.2.2" data-path="sfeonechap.html"><a href="sfeonechap.html#allowing-for-aborts"><i class="fa fa-check"></i><b>17.2.2</b> Allowing for aborts</a></li>
<li class="chapter" data-level="17.2.3" data-path="sfeonechap.html"><a href="sfeonechap.html#some-comments"><i class="fa fa-check"></i><b>17.2.3</b> Some comments:</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="sfeonechap.html"><a href="sfeonechap.html#example-second-price-auction-using-bitcoin"><i class="fa fa-check"></i><b>17.3</b> Example: Second price auction using bitcoin</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="sfeonechap.html"><a href="sfeonechap.html#another-example-distributed-and-threshold-cryptography"><i class="fa fa-check"></i><b>17.3.1</b> Another example: distributed and threshold cryptography</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="sfeonechap.html"><a href="sfeonechap.html#proving-the-fundamental-theorem"><i class="fa fa-check"></i><b>17.4</b> Proving the fundamental theorem:</a></li>
<li class="chapter" data-level="17.5" data-path="sfeonechap.html"><a href="sfeonechap.html#hbctomalred"><i class="fa fa-check"></i><b>17.5</b> Malicious to honest but curious reduction</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="sfeonechap.html"><a href="sfeonechap.html#handling-probabilistic-strategies"><i class="fa fa-check"></i><b>17.5.1</b> Handling probabilistic strategies:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="sfetwochap.html"><a href="sfetwochap.html"><i class="fa fa-check"></i><b>18</b> Multiparty secure computation II: Construction using Fully Homomorphic Encryption</a>
<ul>
<li class="chapter" data-level="18.1" data-path="sfetwochap.html"><a href="sfetwochap.html#constructing-2-party-honest-but-curious-computation-from-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>18.1</b> Constructing 2 party honest but curious computation from fully homomorphic encryption</a></li>
<li class="chapter" data-level="18.2" data-path="sfetwochap.html"><a href="sfetwochap.html#achieving-circuit-privacy-in-a-fully-homomorphic-encryption"><i class="fa fa-check"></i><b>18.2</b> Achieving circuit privacy in a fully homomorphic encryption</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="sfetwochap.html"><a href="sfetwochap.html#bottom-line-a-two-party-secure-computation-protocol"><i class="fa fa-check"></i><b>18.2.1</b> Bottom line: A two party secure computation protocol</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="sfetwochap.html"><a href="sfetwochap.html#beyond-two-parties"><i class="fa fa-check"></i><b>18.3</b> Beyond two parties</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="quantum-computing-and-cryptography-i.html"><a href="quantum-computing-and-cryptography-i.html"><i class="fa fa-check"></i><b>19</b> Quantum computing and cryptography I</a>
<ul>
<li class="chapter" data-level="19.1" data-path="quantum-computing-and-cryptography-i.html"><a href="quantum-computing-and-cryptography-i.html#the-double-slit-experiment"><i class="fa fa-check"></i><b>19.1</b> The double slit experiment</a></li>
<li class="chapter" data-level="19.2" data-path="quantum-computing-and-cryptography-i.html"><a href="quantum-computing-and-cryptography-i.html#quantum-amplitudes"><i class="fa fa-check"></i><b>19.2</b> Quantum amplitudes</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="quantum-computing-and-cryptography-i.html"><a href="quantum-computing-and-cryptography-i.html#quantum-computing-and-computation---an-executive-summary."><i class="fa fa-check"></i><b>19.2.1</b> Quantum computing and computation - an executive summary.</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="quantum-computing-and-cryptography-i.html"><a href="quantum-computing-and-cryptography-i.html#quantum-101"><i class="fa fa-check"></i><b>19.3</b> Quantum 101</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="quantum-computing-and-cryptography-i.html"><a href="quantum-computing-and-cryptography-i.html#physically-realizing-quantum-computation"><i class="fa fa-check"></i><b>19.3.1</b> Physically realizing quantum computation</a></li>
<li class="chapter" data-level="19.3.2" data-path="quantum-computing-and-cryptography-i.html"><a href="quantum-computing-and-cryptography-i.html#bra-ket-notation"><i class="fa fa-check"></i><b>19.3.2</b> Bra-ket notation</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="quantum-computing-and-cryptography-i.html"><a href="quantum-computing-and-cryptography-i.html#bells-inequality"><i class="fa fa-check"></i><b>19.4</b> Bell’s Inequality</a></li>
<li class="chapter" data-level="19.5" data-path="quantum-computing-and-cryptography-i.html"><a href="quantum-computing-and-cryptography-i.html#analysis-of-bells-inequality"><i class="fa fa-check"></i><b>19.5</b> Analysis of Bell’s Inequality</a></li>
<li class="chapter" data-level="19.6" data-path="quantum-computing-and-cryptography-i.html"><a href="quantum-computing-and-cryptography-i.html#grovers-algorithm"><i class="fa fa-check"></i><b>19.6</b> Grover’s Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="quantum-computing-and-cryptography-ii.html"><a href="quantum-computing-and-cryptography-ii.html"><i class="fa fa-check"></i><b>20</b> Quantum computing and cryptography II</a>
<ul>
<li class="chapter" data-level="20.1" data-path="quantum-computing-and-cryptography-ii.html"><a href="quantum-computing-and-cryptography-ii.html#from-order-finding-to-factoring-and-discrete-log"><i class="fa fa-check"></i><b>20.1</b> From order finding to factoring and discrete log</a></li>
<li class="chapter" data-level="20.2" data-path="quantum-computing-and-cryptography-ii.html"><a href="quantum-computing-and-cryptography-ii.html#finding-periods-of-a-function-simons-algorithm"><i class="fa fa-check"></i><b>20.2</b> Finding periods of a function: Simon’s Algorithm</a></li>
<li class="chapter" data-level="20.3" data-path="quantum-computing-and-cryptography-ii.html"><a href="quantum-computing-and-cryptography-ii.html#from-simon-to-shor"><i class="fa fa-check"></i><b>20.3</b> From Simon to Shor</a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="quantum-computing-and-cryptography-ii.html"><a href="quantum-computing-and-cryptography-ii.html#the-fourier-transform-over-mathbbz_m"><i class="fa fa-check"></i><b>20.3.1</b> The Fourier transform over <span class="math inline">\(\mathbb{Z}_m\)</span></a></li>
<li class="chapter" data-level="20.3.2" data-path="quantum-computing-and-cryptography-ii.html"><a href="quantum-computing-and-cryptography-ii.html#quantum-fourier-transform-over-mathbbz_m"><i class="fa fa-check"></i><b>20.3.2</b> Quantum Fourier Transform over <span class="math inline">\(\mathbb{Z}_m\)</span></a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="quantum-computing-and-cryptography-ii.html"><a href="quantum-computing-and-cryptography-ii.html#shor鈥檚-order-finding-algorithm."><i class="fa fa-check"></i><b>20.4</b> Shor鈥檚 Order-Finding Algorithm.</a>
<ul>
<li class="chapter" data-level="20.4.1" data-path="quantum-computing-and-cryptography-ii.html"><a href="quantum-computing-and-cryptography-ii.html#analysis-the-case-that-rm"><i class="fa fa-check"></i><b>20.4.1</b> Analysis: the case that <span class="math inline">\(r|m\)</span></a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="quantum-computing-and-cryptography-ii.html"><a href="quantum-computing-and-cryptography-ii.html#rational-approximation-of-real-numbers"><i class="fa fa-check"></i><b>20.5</b> Rational approximation of real numbers</a>
<ul>
<li class="chapter" data-level="20.5.1" data-path="quantum-computing-and-cryptography-ii.html"><a href="quantum-computing-and-cryptography-ii.html#quantum-cryptography"><i class="fa fa-check"></i><b>20.5.1</b> Quantum cryptography</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="software-obfuscation.html"><a href="software-obfuscation.html"><i class="fa fa-check"></i><b>21</b> Software Obfuscation</a>
<ul>
<li class="chapter" data-level="21.1" data-path="software-obfuscation.html"><a href="software-obfuscation.html#witness-encryption"><i class="fa fa-check"></i><b>21.1</b> Witness encryption</a></li>
<li class="chapter" data-level="21.2" data-path="software-obfuscation.html"><a href="software-obfuscation.html#deniable-encryption"><i class="fa fa-check"></i><b>21.2</b> Deniable encryption</a></li>
<li class="chapter" data-level="21.3" data-path="software-obfuscation.html"><a href="software-obfuscation.html#functional-encryption"><i class="fa fa-check"></i><b>21.3</b> Functional encryption</a></li>
<li class="chapter" data-level="21.4" data-path="software-obfuscation.html"><a href="software-obfuscation.html#the-software-patch-problem"><i class="fa fa-check"></i><b>21.4</b> The software patch problem</a></li>
<li class="chapter" data-level="21.5" data-path="software-obfuscation.html"><a href="software-obfuscation.html#software-obfuscation-1"><i class="fa fa-check"></i><b>21.5</b> Software obfuscation</a></li>
<li class="chapter" data-level="21.6" data-path="software-obfuscation.html"><a href="software-obfuscation.html#applications-of-obfuscation"><i class="fa fa-check"></i><b>21.6</b> Applications of obfuscation</a></li>
<li class="chapter" data-level="21.7" data-path="software-obfuscation.html"><a href="software-obfuscation.html#impossibility-of-obfuscation"><i class="fa fa-check"></i><b>21.7</b> Impossibility of obfuscation</a>
<ul>
<li class="chapter" data-level="21.7.1" data-path="software-obfuscation.html"><a href="software-obfuscation.html#proof-of-impossibility-of-vbb-obfuscation"><i class="fa fa-check"></i><b>21.7.1</b> Proof of impossibility of VBB obfuscation</a></li>
</ul></li>
<li class="chapter" data-level="21.8" data-path="software-obfuscation.html"><a href="software-obfuscation.html#indistinguishability-obfuscation"><i class="fa fa-check"></i><b>21.8</b> Indistinguishability obfuscation</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="more-obfuscation-exotic-encryptions.html"><a href="more-obfuscation-exotic-encryptions.html"><i class="fa fa-check"></i><b>22</b> More obfuscation, exotic encryptions</a>
<ul>
<li class="chapter" data-level="22.1" data-path="more-obfuscation-exotic-encryptions.html"><a href="more-obfuscation-exotic-encryptions.html#slower-weaker-less-securer"><i class="fa fa-check"></i><b>22.1</b> Slower, weaker, less securer</a></li>
<li class="chapter" data-level="22.2" data-path="more-obfuscation-exotic-encryptions.html"><a href="more-obfuscation-exotic-encryptions.html#how-to-get-ibe-from-pairing-based-assumptions."><i class="fa fa-check"></i><b>22.2</b> How to get IBE from pairing based assumptions.</a></li>
<li class="chapter" data-level="22.3" data-path="more-obfuscation-exotic-encryptions.html"><a href="more-obfuscation-exotic-encryptions.html#beyond-pairing-based-cryptography"><i class="fa fa-check"></i><b>22.3</b> Beyond pairing based cryptography</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="anonymous-communication.html"><a href="anonymous-communication.html"><i class="fa fa-check"></i><b>23</b> Anonymous communication</a>
<ul>
<li class="chapter" data-level="23.1" data-path="anonymous-communication.html"><a href="anonymous-communication.html#steganography"><i class="fa fa-check"></i><b>23.1</b> Steganography</a></li>
<li class="chapter" data-level="23.2" data-path="anonymous-communication.html"><a href="anonymous-communication.html#anonymous-routing"><i class="fa fa-check"></i><b>23.2</b> Anonymous routing</a></li>
<li class="chapter" data-level="23.3" data-path="anonymous-communication.html"><a href="anonymous-communication.html#tor"><i class="fa fa-check"></i><b>23.3</b> Tor</a></li>
<li class="chapter" data-level="23.4" data-path="anonymous-communication.html"><a href="anonymous-communication.html#telex"><i class="fa fa-check"></i><b>23.4</b> Telex</a></li>
<li class="chapter" data-level="23.5" data-path="anonymous-communication.html"><a href="anonymous-communication.html#riposte"><i class="fa fa-check"></i><b>23.5</b> Riposte</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="ethical-moral-and-policy-dimensions-to-cryptography.html"><a href="ethical-moral-and-policy-dimensions-to-cryptography.html"><i class="fa fa-check"></i><b>24</b> Ethical, moral, and policy dimensions to cryptography</a>
<ul>
<li class="chapter" data-level="24.1" data-path="ethical-moral-and-policy-dimensions-to-cryptography.html"><a href="ethical-moral-and-policy-dimensions-to-cryptography.html#reading-prior-to-lecture"><i class="fa fa-check"></i><b>24.1</b> Reading prior to lecture:</a></li>
<li class="chapter" data-level="24.2" data-path="ethical-moral-and-policy-dimensions-to-cryptography.html"><a href="ethical-moral-and-policy-dimensions-to-cryptography.html#case-studies."><i class="fa fa-check"></i><b>24.2</b> Case studies.</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="ethical-moral-and-policy-dimensions-to-cryptography.html"><a href="ethical-moral-and-policy-dimensions-to-cryptography.html#the-snowden-revelations"><i class="fa fa-check"></i><b>24.2.1</b> The Snowden revelations</a></li>
<li class="chapter" data-level="24.2.2" data-path="ethical-moral-and-policy-dimensions-to-cryptography.html"><a href="ethical-moral-and-policy-dimensions-to-cryptography.html#fbi-vs-apple-case"><i class="fa fa-check"></i><b>24.2.2</b> FBI vs Apple case</a></li>
<li class="chapter" data-level="24.2.3" data-path="ethical-moral-and-policy-dimensions-to-cryptography.html"><a href="ethical-moral-and-policy-dimensions-to-cryptography.html#juniper-backdoor-case-and-the-opm-break-in"><i class="fa fa-check"></i><b>24.2.3</b> Juniper backdoor case and the OPM break-in</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="course-recap.html"><a href="course-recap.html"><i class="fa fa-check"></i><b>25</b> Course recap</a>
<ul>
<li class="chapter" data-level="25.1" data-path="course-recap.html"><a href="course-recap.html#some-things-we-did-not-cover"><i class="fa fa-check"></i><b>25.1</b> Some things we did not cover</a></li>
<li class="chapter" data-level="25.2" data-path="course-recap.html"><a href="course-recap.html#what-i-hope-you-learned"><i class="fa fa-check"></i><b>25.2</b> What I hope you learned</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal Book Example</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="computational-security" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">3</span> Computational Security<a href="computational-security.html#computational-security" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><strong>Additional reading:</strong> Sections 2.2 and 2.3 in Boneh-Shoup book. Chapter 3 up to and including Section 3.3 in Katz-Lindell book.</p>
<p>Recall our cast of characters- Alice and Bob want to communicate securely over a
channel that is monitored by the nosy Eve. In the last lecture, we have seen the
definition of <em>perfect secrecy</em> that guarantees that Eve cannot learn <em>anything</em>
about their communication beyond what she already knew. However, this security
came at a price. For every bit of communication, Alice and Bob have to exchange
in advance a bit of a secret key. In fact, the proof of this result gives rise
to the following simple Python program that can break every encryption
scheme that uses, say, a <span class="math inline">\(128\)</span> bit key, with a <span class="math inline">\(129\)</span> bit message:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="computational-security.html#cb1-1" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> product <span class="co"># Import an iterator for cartesian products</span></span>
<span id="cb1-2"><a href="computational-security.html#cb1-2" tabindex="-1"></a><span class="im">from</span> random <span class="im">import</span> choice <span class="co"># choose random element of list</span></span>
<span id="cb1-3"><a href="computational-security.html#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="computational-security.html#cb1-4" tabindex="-1"></a><span class="co"># Gets ciphertext as input and two potential plaintexts</span></span>
<span id="cb1-5"><a href="computational-security.html#cb1-5" tabindex="-1"></a><span class="co"># Returns most likely plaintext</span></span>
<span id="cb1-6"><a href="computational-security.html#cb1-6" tabindex="-1"></a><span class="co"># We assume we have access to the function Encrypt(key,plaintext)</span></span>
<span id="cb1-7"><a href="computational-security.html#cb1-7" tabindex="-1"></a><span class="kw">def</span> Distinguish(ciphertext,plaintext1,plaintext2):</span>
<span id="cb1-8"><a href="computational-security.html#cb1-8" tabindex="-1"></a>    <span class="cf">for</span> key <span class="kw">in</span> product([<span class="dv">0</span>,<span class="dv">1</span>], repeat <span class="op">=</span> <span class="dv">128</span>): <span class="co"># Iterate over all possible keys of length 128</span></span>
<span id="cb1-9"><a href="computational-security.html#cb1-9" tabindex="-1"></a>        <span class="cf">if</span> Encrypt(key, plaintext1)<span class="op">==</span>ciphertext:</span>
<span id="cb1-10"><a href="computational-security.html#cb1-10" tabindex="-1"></a>            <span class="cf">return</span> plaintext1</span>
<span id="cb1-11"><a href="computational-security.html#cb1-11" tabindex="-1"></a>        <span class="cf">if</span> Encrypt(key, plaintext2)<span class="op">==</span>ciphertext:</span>
<span id="cb1-12"><a href="computational-security.html#cb1-12" tabindex="-1"></a>            <span class="cf">return</span> plaintext2</span>
<span id="cb1-13"><a href="computational-security.html#cb1-13" tabindex="-1"></a>    <span class="cf">return</span> choice([plaintext1,plaintext2])</span></code></pre></div>
<p>The program <code>Distinguish</code> will break any <span class="math inline">\(128\)</span>-bit key and <span class="math inline">\(129\)</span>-bit message encryption <code>Encrypt</code>, in the sense that there exist a pair of messages
<span class="math inline">\(m_0,m_1\)</span> such that <code>Distinguish</code><span class="math inline">\((\)</span><code>Encrypt</code><span class="math inline">\((k,m_b),m_0,m_1)=m_b\)</span> with probability at least <span class="math inline">\(0.75\)</span> over <span class="math inline">\(k \leftarrow_R \{0,1\}^n\)</span> and <span class="math inline">\(b \leftarrow_R \{0,1\}\)</span>.</p>
<p>Now, generating, distributing, and protecting huge keys causes immense
logistical problems, which is why almost all encryption schemes used in practice
do in fact utilize short keys (e.g., <span class="math inline">\(128\)</span> bits long) with messages that can be
much longer (sometimes even terabytes or more of data).</p>
<p>So, why can’t we use the above Python program to break all encryptions in the
Internet and win infamy and fortune? We can in fact, but we’ll have to wait a
<em>really</em> long time, since the loop in <code>Distinguish</code> will run <span class="math inline">\(2^{128}\)</span> times,
which will take much more than the lifetime of the universe to complete, even if
we used all the computers on the planet.</p>
<p>However, the fact that <em>this</em> particular program is not a feasible attack, does
not mean there does not exist a different attack. But this still suggests a
tantalizing possibility: if we consider a relaxed version of perfect secrecy that
restricts Eve to performing computations that can be done in this universe
(e.g., less than <span class="math inline">\(2^{256}\)</span> steps should be safe not just for human but for all
potential alien civilizations) then can we bypass the impossibility result and
allow the key to be much shorter than the message?</p>
<p>This in fact does seem to be the case, but as we’ve seen, defining security is a
subtle task, and will take some care. As before, the way we avoid (at least some
of) the pitfalls of so many cryptosystems in history is that we insist on very
precisely <em>defining</em> what it means for a scheme to be secure.</p>
<p>Let us defer the discussion how one defines a function being computable in “less
than <span class="math inline">\(T\)</span> operations” and just say that there is a way to formally do so. We will want to say that a scheme has “<span class="math inline">\(256\)</span> bits of security” if it is not possible to break it using less than <span class="math inline">\(2^{256}\)</span> operations,
and more generally that it has <span class="math inline">\(t\)</span> bits of security if it can’t be broken using less than <span class="math inline">\(2^t\)</span>
operations.
Given the perfect secrecy definition we saw last time, a natural attempt for defining
computational secrecy would be the following:</p>
<blockquote>
<h1 id="firstcompdef" class="definition" title="Computational secrecy (first attempt)"></h1>
<p>An encryption scheme <span class="math inline">\((E,D)\)</span> has <em><span class="math inline">\(t\)</span> bits of computational secrecy</em>
if for every two distinct plaintexts <span class="math inline">\(\{m_0,m_1\} \subseteq {\{0,1\}}^\ell\)</span> and every strategy of Eve using at most <span class="math inline">\(2^t\)</span> computational steps, if we choose at random <span class="math inline">\(b\in{\{0,1\}}\)</span> and a random key <span class="math inline">\(k\in{\{0,1\}}^n\)</span>, then the probability that Eve guesses <span class="math inline">\(m_b\)</span> after seeing <span class="math inline">\(E_k(m_b)\)</span> is at most <span class="math inline">\(1/2\)</span>.</p>
</blockquote>
<p><strong>Note:</strong> It is important to keep track of what is known and unknown to the adversary Eve. The adversary knows the set <span class="math inline">\(\{ m_0,m_1 \}\)</span> of potential messages, and the ciphertext <span class="math inline">\(y=E_k(m_b)\)</span>. The only things she doesn’t know are whether <span class="math inline">\(b=0\)</span> or <span class="math inline">\(b=1\)</span>, and the value of the secret key <span class="math inline">\(k\)</span>. In particular, because <span class="math inline">\(m_0\)</span> and <span class="math inline">\(m_1\)</span> are known to Eve, it does not matter whether we define Eve’s goal in this “security game” as outputting <span class="math inline">\(m_b\)</span> or as outputting <span class="math inline">\(b\)</span>.</p>
<p><a href="" class="ref">firstcompdef</a> seems very natural, but is in fact <em>impossible</em> to achieve if the key is shorter than the message.</p>
<blockquote>
<h1 id="section-22" class="pause"></h1>
<p>Before reading further, you might want to stop and think if you can <em>prove</em> that there is no, say, encryption scheme with <span class="math inline">\(\sqrt{n}\)</span> bits of computational security satisfying <a href="" class="ref">firstcompdef</a> with <span class="math inline">\(\ell = n+1\)</span> and where the time to compute the encryption is polynomial.</p>
</blockquote>
<p>The reason <a href="" class="ref">firstcompdef</a> can’t be achieved is that if the message is even one bit
longer than the key, we can always have a very efficient procedure
that achieves success probability of about <span class="math inline">\(1/2 + 2^{-n-1}\)</span> by guessing the key. This is because we can replace the loop in the Python program <code>Distinguish</code> by choosing the key at random. Since we have some small chance of guessing correctly, we will get a small advantage over half.</p>
<p>Of course an advantage of <span class="math inline">\(2^{-256}\)</span> in guessing the message is not really something we would worry about.
For example, since the earth is about 5 billion years old, we can estimate the chance that an asteroid of the magnitude that caused the dinosaurs’ extinction will hit us this very second to be about <span class="math inline">\(2^{-60}\)</span>.
Hence we want to relax the notion of computational security so it would not consider guessing with such a tiny advantage as a “true break” of the scheme.
The resulting definition is the following:</p>
<blockquote>
<h1 id="compsecconcdef" class="definition" title="Computational secrecy (concrete)"></h1>
<p>An encryption scheme <span class="math inline">\((E,D)\)</span> has <em><span class="math inline">\(t\)</span> bits of computational secrecy<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></em> if for every two distinct plaintexts <span class="math inline">\(\{m_0,m_1\} \subseteq {\{0,1\}}^\ell\)</span> and every strategy of Eve using at most <span class="math inline">\(2^t\)</span> computational steps, if we choose at random <span class="math inline">\(b\in{\{0,1\}}\)</span> and a random key <span class="math inline">\(k\in{\{0,1\}}^n\)</span>, then the probability that Eve guesses <span class="math inline">\(m_b\)</span> after seeing <span class="math inline">\(E_k(m_b)\)</span> is at most <span class="math inline">\(1/2+2^{-t}\)</span>.</p>
</blockquote>
<p>Having learned our lesson, let’s try to see that this strategy does give us the
kind of conditions we desired. In particular, let’s verify that this definition
implies the analogous condition to perfect secrecy.</p>
<blockquote>
<h1 id="twotomanycomp" class="theorem" title="Guessing game for computational secrecy"></h1>
<p>If <span class="math inline">\((E,D)\)</span> has <span class="math inline">\(t\)</span> bits of computational secrecy as per <a href="" class="ref">compsecconcdef</a> then for every subset <span class="math inline">\(M \subseteq {\{0,1\}}^\ell\)</span> and every strategy of Eve using at most
<span class="math inline">\(2^t-(100\ell+100)\)</span> computational steps, if we choose at random <span class="math inline">\(m\in M\)</span> and a
random key <span class="math inline">\(k\in{\{0,1\}}^n\)</span>, then the probability that Eve guesses <span class="math inline">\(m\)</span> after
seeing <span class="math inline">\(E_k(m)\)</span> is at most <span class="math inline">\(1/|M|+2^{-t+1}\)</span>.</p>
</blockquote>
<p>Before proving this theorem note that it gives us a pretty strong guarantee. In
the exercises we will strengthen it even further showing that no matter what
prior information Eve had on the message before, she will never get any
non-negligible new information on it.<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a>
One way to phrase it is that if the sender used a <span class="math inline">\(256\)</span>-bit secure encryption to encrypt a message, then your
chances of getting to learn any additional information about it before the
universe collapses are more or less the same as the chances that a fairy will
materialize and whisper it in your ear.</p>
<blockquote>
<h1 id="section-23" class="pause"></h1>
<p>Before reading the proof, try to again review the proof of <a href="" class="ref">twotomanythm</a>, and see if you can generalize it yourself to the computational setting.</p>
</blockquote>
<div class="proof" data-ref="twotomanycomp">
<p><span id="unlabeled-div-7" class="proof"><em>Proof</em>. </span>The proof is rather similar to the equivalence of guessing one of two
messages vs. one of many messages for perfect secrecy (i.e., <a href="" class="ref">twotomanythm</a>). However, in the
computational context we need to be careful in keeping track of Eve’s running time.
In the proof of <a href="" class="ref">twotomanythm</a> we showed that if there exists:</p>
<ul>
<li>A subset <span class="math inline">\(M\subseteq {\{0,1\}}^\ell\)</span> of messages</li>
</ul>
<p>and</p>
<ul>
<li><p>An adversary <span class="math inline">\(Eve:{\{0,1\}}^o\rightarrow{\{0,1\}}^\ell\)</span> such that</p>
<p><span class="math display">\[
\Pr_{m{\leftarrow_{\tiny R}}M, k{\leftarrow_{\tiny R}}{\{0,1\}}^n}[ Eve(E_k(m))=m ] &gt; 1/|M|
\]</span></p></li>
</ul>
<p>Then there exist two messages <span class="math inline">\(m_0,m_1\)</span> and an adversary
<span class="math inline">\(Eve&#39;:{\{0,1\}}^o\rightarrow{\{0,1\}}^\ell\)</span> such that <span class="math inline">\(\Pr_{b{\leftarrow_{\tiny R}}{\{0,1\}},k{\leftarrow_{\tiny R}}{\{0,1\}}^n}[Eve&#39;(E_k(m_b))=m_b ] &gt; 1/2\)</span>.</p>
<p>To adapt this proof to the computational setting and complete the proof of the
current theorem it suffices to show that:</p>
<ul>
<li><p>If the probability of <span class="math inline">\(Eve\)</span> succeeding was <span class="math inline">\(\tfrac{1}{|M|} + \epsilon\)</span> then the probability of <span class="math inline">\(Eve&#39;\)</span> succeeding is at least <span class="math inline">\(\tfrac{1}{2} + \epsilon/2\)</span>.</p></li>
<li><p>If <span class="math inline">\(Eve\)</span> can be computed in <span class="math inline">\(T\)</span> operations, then <span class="math inline">\(Eve&#39;\)</span> can be computed in <span class="math inline">\(T + 100\ell + 100\)</span> operations.</p></li>
</ul>
<p>This will imply that if <span class="math inline">\(Eve\)</span> ran in polynomial time and had polynomial advantage over <span class="math inline">\(1/|M|\)</span> in guessing a plaintext chosen from <span class="math inline">\(M\)</span>, then <span class="math inline">\(Eve&#39;\)</span> would run in polynomial time and have polynomial advantage over <span class="math inline">\(1/2\)</span> in guessing a plaintext chosen from <span class="math inline">\(\{ m_0,m_1\}\)</span>.</p>
<p>The first item can be shown by simply doing the same proof more carefully,
keeping track how the advantage over <span class="math inline">\(\tfrac{1}{|M|}\)</span> for <span class="math inline">\(Eve\)</span> translates into
an advantage over <span class="math inline">\(\tfrac{1}{2}\)</span> for <span class="math inline">\(Eve&#39;\)</span>.
As the world’s most annoying saying goes, doing this is an excellent exercise for the reader.</p>
<p>The second item is obtained by looking at the definition of <span class="math inline">\(Eve&#39;\)</span> from that proof. On input <span class="math inline">\(c\)</span>, <span class="math inline">\(Eve&#39;\)</span>
computed <span class="math inline">\(m=Eve(c)\)</span> (which costs <span class="math inline">\(T\)</span> operations), checked if <span class="math inline">\(m=m_0\)</span>
(which costs, say, at most <span class="math inline">\(5\ell\)</span> operations), and then outputted either <span class="math inline">\(1\)</span> or a
random bit (which is a constant, say at most <span class="math inline">\(100\)</span> operations).</p>
</div>
<div id="proof-by-reduction" class="section level3 hasAnchor" number="3.0.1">
<h3><span class="header-section-number">3.0.1</span> Proof by reduction<a href="computational-security.html#proof-by-reduction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The proof of <a href="" class="ref">twotomanycomp</a> is a model to how a great many of the
results in this course will look like. Generally we will have many theorems of
the form:</p>
<blockquote>
<p>“If there is a scheme <span class="math inline">\(S&#39;\)</span> satisfying security definition <span class="math inline">\(X&#39;\)</span> then there is a scheme <span class="math inline">\(S\)</span> satisfying security definition <span class="math inline">\(X\)</span>”</p>
</blockquote>
<p>In the context of <a href="" class="ref">twotomanycomp</a>, <span class="math inline">\(X&#39;\)</span> was “having <span class="math inline">\(t\)</span> bits of security” (in the context distinguishing
between encryptions of two ciphertexts) and <span class="math inline">\(X\)</span> was the more general notion of
hardness of getting a non-trivial advantage over guessing for an encryption of a
random <span class="math inline">\(m\in M\)</span>.
While in <a href="" class="ref">twotomanycomp</a> the encryption scheme <span class="math inline">\(S\)</span> was the same as <span class="math inline">\(S&#39;\)</span>, this need not always be the case.
However, all of the proofs of such statements will have the same global
structure— we will assume towards a contradiction, that there is an efficient
adversary strategy <span class="math inline">\(Eve\)</span> demonstrating that the scheme <span class="math inline">\(S\)</span> violates the security notion <span class="math inline">\(X\)</span>, and build from
<span class="math inline">\(Eve\)</span> a strategy <span class="math inline">\(Eve&#39;\)</span> demonstrating that <span class="math inline">\(S&#39;\)</span> violates <span class="math inline">\(X&#39;\)</span>. This is such an
important point that it deserves repeating:</p>
<blockquote>
<p><em>The way you show that if <span class="math inline">\(S&#39;\)</span> is secure then <span class="math inline">\(S\)</span> is secure is by giving
a transformation from an adversary that breaks <span class="math inline">\(S\)</span> into an adversary that
breaks <span class="math inline">\(S&#39;\)</span></em></p>
</blockquote>
<p>For computational secrecy, we will always want that <span class="math inline">\(Eve&#39;\)</span> will be efficient if
<span class="math inline">\(Eve\)</span> is, and that will usually be the case because <span class="math inline">\(Eve&#39;\)</span> will simply use <span class="math inline">\(Eve\)</span>
as a black box, which it will not invoke too many times, and addition will use
some polynomial time preprocessing and postprocessing. The more challenging
parts of such proofs are typically:</p>
<ul>
<li><p>Coming up with the strategy <span class="math inline">\(Eve&#39;\)</span>.</p></li>
<li><p>Analyzing the probability of success and in particular showing that if <span class="math inline">\(Eve\)</span>
had non-negligible advantage then so will <span class="math inline">\(Eve&#39;\)</span>.</p></li>
</ul>
<div class="float" id="reductiongenfig">
<img src="../figure/reduction.jpg" class="margin" alt="We show that the security of S&#39; implies the security of S by transforming an adversary Eve breaking S into an adversary Eve&#39; breaking S&#39;." />
<div class="figcaption">We show that the security of <span class="math inline">\(S&#39;\)</span> implies the security of <span class="math inline">\(S\)</span> by transforming an adversary <span class="math inline">\(Eve\)</span> breaking <span class="math inline">\(S\)</span> into an adversary <span class="math inline">\(Eve&#39;\)</span> breaking <span class="math inline">\(S&#39;\)</span>.</div>
</div>
<p>Note that, just like in the context of NP completeness or uncomputability reductions, security reductions work <em>backwards</em>.
That is, we construct the scheme <span class="math inline">\(S\)</span> based on the scheme <span class="math inline">\(S&#39;\)</span>, but then prove that we can transform an algorithm breaking <span class="math inline">\(S\)</span> into an algorithm breaking <span class="math inline">\(S&#39;\)</span>.
Just like in computational complexity, it can sometimes be hard to keep track of the direction of the reduction.
In fact, cryptographic reductions can be even subtler, since they involve an interplay of several entities (for example, sender, receiver, and adversary) and probabilistic choices (e.g., over the message to be sent and the key).</p>
</div>
<div id="the-asymptotic-approach" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> The asymptotic approach<a href="computational-security.html#the-asymptotic-approach" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For practical security, often every bit of security matters.
We want our keys to be as short as possible and our schemes to be as fast as possible while satisfying a particular level of security.
In practice we would usually like to ensure that when we use a smallish security parameter such as <span class="math inline">\(n\)</span> in the few hundreds or thousands then:</p>
<ul>
<li><p>The <em>honest parties</em> (the parties running the encryption and decryption algorithms) are extremely efficient, something like 100-1000 cycles per byte of data processed. In theory terms we would want them be using an <span class="math inline">\(O(n)\)</span> or at worst <span class="math inline">\(O(n^2)\)</span> time algorithms with not-too-big hidden constants.</p></li>
<li><p>We want to protect against <em>adversaries</em> (the parties trying to break the encryption) that have much vaster computational capabilities. A typical modern encryption is built so that using standard key sizes it can withstand the combined computational powers of all computers on earth for several decades. In theory terms we would want the time to break the scheme to be <span class="math inline">\(2^{\Omega(n)}\)</span> (or if not, at least <span class="math inline">\(2^{\Omega(\sqrt{n})}\)</span> or <span class="math inline">\(2^{\Omega(n^{1/3})}\)</span>) with not too small hidden constants.</p></li>
</ul>
<p>For implementing cryptography in practice, the tradeoff between security and efficiency can be crucial. However, for understanding the <em>principles</em> behind cryptography, keeping track of concrete security can be a distraction, and so just like we do in algorithms courses, we will use <em>asymptotic analysis</em> (also known as <em>big Oh notation</em>) to sweep many of those details under the carpet.</p>
<p>To a first approximation, there will be only two types of running times we will
encounter in this course:</p>
<ul>
<li><p><em>Polynomial</em> running time of the form <span class="math inline">\(d\cdot n^c\)</span> for some constants
<span class="math inline">\(d,c&gt;0\)</span> (or <span class="math inline">\(poly(n)=n^{O(1)}\)</span> for short), which we will consider as
<em>efficient</em>.</p></li>
<li><p><em>Exponential</em> running time of the form <span class="math inline">\(2^{d\cdot n^{\epsilon}}\)</span> for some
constants <span class="math inline">\(d,\epsilon &gt;0\)</span> (or <span class="math inline">\(2^{n^{\Omega(1)}}\)</span> for short) which we will
consider as <em>infeasible</em>.<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></p></li>
</ul>
<p>Another way to say it is that in this course, if a scheme has any security at all, it will have at least <span class="math inline">\(n^{\epsilon}\)</span> bits of security where <span class="math inline">\(n\)</span> is the length of the key and <span class="math inline">\(\epsilon&gt;0\)</span> is some absolute constant such as <span class="math inline">\(\epsilon=1/3\)</span>.
Hence in this course, whenever you hear the term “super polynomial”, you can equate it in your mind with “exponential” and you won’t be far off the truth.</p>
<p>These are not all the theoretically possible running times.
One can have intermediate functions such as <span class="math inline">\(n^{\log n}\)</span> though we will generally not
encounter those.
To make things clean (and to correspond to standard terminology), we will generally associate “efficient computation” with <em>polynomial time</em> in <span class="math inline">\(n\)</span> where <span class="math inline">\(n\)</span> is either its input length or the key size (the key size and input length will always be polynomially related, and so this choice won’t matter). We want our algorithms (encryption, decryption, etc.) to be computable in polynomial time, but to require <em>super polynomial time</em> to break.</p>
<p><strong>Negligible probabilities.</strong> In cryptography, we care not just about the running time of the adversary but also about their probability of success (which should be as small as possible).
If <span class="math inline">\(\mu:\N \rightarrow [0,\infty)\)</span> is a function (which we’ll often think of as corresponding to the adversary’s probability of success or advantage over the trivial probability, as a function of the key size <span class="math inline">\(n\)</span>) then we say that <span class="math inline">\(\mu(n)\)</span> is <em>negligible</em> if it’s smaller than the inverse of every (positive) polynomial. Our security definitions will have the following form:</p>
<blockquote>
<p><em>“Scheme <span class="math inline">\(S\)</span> is secure if for every polynomial <span class="math inline">\(p(\cdot)\)</span> and <span class="math inline">\(p(n)\)</span> time adversary <span class="math inline">\(Eve\)</span>, there is some negligible function <span class="math inline">\(\mu\)</span> such that the probability that <span class="math inline">\(Eve\)</span> succeeds in the security game for <span class="math inline">\(S\)</span> is at most <span class="math inline">\(trivial + \mu(n)\)</span></em>”</p>
</blockquote>
<p>We now make these notions more formal.</p>
<div class="definition" title="Negligible function">
<p><span id="def:negligibledef" class="definition"><strong>Definition 3.1  </strong></span>A function <span class="math inline">\(\mu:\mathbb{N} \rightarrow [0,\infty)\)</span> is <em>negligible</em> if for every polynomial <span class="math inline">\(p:\N \rightarrow \N\)</span> there exists <span class="math inline">\(N \in \N\)</span> such that <span class="math inline">\(\mu(n) &lt; \tfrac{1}{p(n)}\)</span> for every <span class="math inline">\(n&gt;N\)</span>.<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a></p>
</div>
<p>The following exercise provides a good way to get some comfort with this definition:</p>
<div class="exercise" title="Negligible functions properties">
<p><span id="exr:negligible" class="exercise"><strong>Exercise 3.1  </strong></span></p>
<ol style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(\mu:\N \rightarrow [0,\infty)\)</span> be a negligible function. Prove that for every polynomials <span class="math inline">\(p,q:\mathbb{R}\rightarrow \mathbb{R}\)</span> with non-negative coefficients such that <span class="math inline">\(p(0) = 0\)</span>, the function <span class="math inline">\(\mu&#39;:\N \rightarrow [0,\infty)\)</span> defined as <span class="math inline">\(\mu&#39;(n) = p(\mu(q(n)))\)</span> is negligible.</p></li>
<li><p>Let <span class="math inline">\(\mu:\N \rightarrow [0,\infty)\)</span>. Prove that <span class="math inline">\(\mu\)</span> is negligible if and only if for every constant <span class="math inline">\(c\)</span>, <span class="math inline">\(\lim_{n \rightarrow \infty} n^c \mu(n) = 0\)</span>.</p></li>
</ol>
</div>
<div class="remark" title="Asymptotic analysis">
<p><span id="asymptotic" class="remark"><em>Remark</em>. </span>The above definitions could be confusing if you haven’t encountered asymptotic analysis before. Reading the beginning of Chapter 3 (pages 43-51) in the KL book, as well as the mathematical background lecture in my <a href="http://www.introtcs.org/public/index.html">intro to TCS notes</a> can be extremely useful. As a rule of thumb, if every time you see the word “polynomial” you imagine the function <span class="math inline">\(n^{10}\)</span> and every time you see the word “negligible” you imagine the function <span class="math inline">\(2^{-\sqrt{n}}\)</span> then you will get the right intuition.</p>
<p>What you need to remember is that negligible is much smaller than any inverse polynomial, while polynomials are closed under multiplication, and so we have the “equations”</p>
<p><span class="math display">\[negligible\times polynomial = negligible\]</span></p>
<p>and</p>
<p><span class="math display">\[polynomial \times polynomial = polynomial\]</span></p>
<p>As mentioned, in practice people really want to get as close as possible to <span class="math inline">\(n\)</span> bits of security with an <span class="math inline">\(n\)</span> bit key, but we would be happy as long as the security grows with the key, so when we say a scheme is “secure” you can think of it having <span class="math inline">\(\sqrt{n}\)</span> bits of security (though any function growing faster than <span class="math inline">\(\log n\)</span> would be fine as well).</p>
</div>
<p>From now on, we will require all of our encryption schemes to be <em>efficient</em>
which means that the encryption and decryption algorithms should run in
polynomial time. Security will mean that any efficient adversary can make at
most a negligible gain in the probability of guessing the message over its a
priori probability.<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a></p>
<p>We can now formally define computational secrecy in asymptotic terms:</p>
<blockquote>
<h1 id="compsecdef" class="definition" title="Computational secrecy (asymptotic)"></h1>
<p>An encryption scheme <span class="math inline">\((E,D)\)</span> is <em>computationally secret</em> if for every two distinct plaintexts <span class="math inline">\(\{m_0,m_1\} \subseteq {\{0,1\}}^\ell\)</span> and every efficient (i.e., polynomial time) strategy of Eve, if we choose at
random <span class="math inline">\(b\in{\{0,1\}}\)</span> and a random key <span class="math inline">\(k\in{\{0,1\}}^n\)</span>, then the probability
that Eve guesses <span class="math inline">\(m_b\)</span> after seeing <span class="math inline">\(E_k(m_b)\)</span> is at most <span class="math inline">\(1/2+\mu(n)\)</span> for some
negligible function <span class="math inline">\(\mu(\cdot)\)</span>.</p>
</blockquote>
<div id="countoperation" class="section level3 hasAnchor" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Counting number of operations.<a href="computational-security.html#countoperation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One more detail that we’ve so far ignored is what does it mean exactly for a
function to be computable using at most <span class="math inline">\(T\)</span> operations.
Fortunately, when we don’t really care about the difference between <span class="math inline">\(T\)</span> and, say, <span class="math inline">\(T^2\)</span>, then
essentially every reasonable definition gives the same answer.<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a>
Formally, we can use the notions of Turing machines, Boolean circuits, or straightline programs to define complexity. For concreteness, let’s define that a function <span class="math inline">\(F:{\{0,1\}}^n\rightarrow{\{0,1\}}^m\)</span>
has complexity at most <span class="math inline">\(T\)</span> if there is a Boolean circuit that computes <span class="math inline">\(F\)</span> using at most <span class="math inline">\(T\)</span> Boolean gates (say AND/OR/NOT or NAND; alternatively you can choose your favorite universal gate sets.)
We will often also consider <em>probabilistic</em> functions in which case we allow the circuit a RAND gate that
outputs a single random bit (though this in general does not give extra power).
The fact that we only care about asymptotics means you don’t really need to
think of gates when arguing in cryptography. However, it is comforting to
know that this notion has a precise mathematical formulation.</p>
<p><strong>Uniform vs non-uniform models.</strong> While many computational texts focus on models such as Turing machines, in cryptography it is more convenient to use Boolean circuits which are a <a href="https://introtcs.org/public/lec_11_running_time.html#nonuniformcompsec">non uniform model</a> of computation in the sense that we allow a different circuit for every given input length. The reasons are the following:</p>
<ol style="list-style-type: decimal">
<li><p>Circuits can express <em>finite</em> computation, while Turing machines only make sense for computing on arbitrarily large input lengths, and so we can make sense of notions such as “<span class="math inline">\(t\)</span> bits of computational security”.</p></li>
<li><p>Circuits allow the notion of “hardwiring” whereby if we can compute a certain function <span class="math inline">\(F:\{0,1\}^{n+s} \rightarrow \{0,1\}^m\)</span> using a circuit of <span class="math inline">\(T\)</span> gates and have a string <span class="math inline">\(w \in \{0,1\}^s\)</span> then we can compute the function <span class="math inline">\(x \mapsto F(xw)\)</span> using <span class="math inline">\(T\)</span> gates as well. This is useful in many cryptograhic proofs.</p></li>
</ol>
<p>One can build the theory of cryptography using Turing machines as well, but it is more cumbersome.</p>
<div class="remark" title="Computing beyond functions">
<p><span id="computebeyondfunctions" class="remark"><em>Remark</em>. </span>Later on in the course, both our cryptographic schemes and the adversaries will extend beyond simple functions that map an input to an output, and we will consider <em>interactive algorithms</em> that exchange messages with one another. Such an algorithm can be implemented using circuits or Turing machines that take as input the prior state and the history of messages up to a certain point in the interaction, and output the next message in the interaction. The number of operations used in such a strategy is the total number of gates used in computing all the messages.</p>
</div>
</div>
</div>
<div id="our-first-conjecture" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Our first conjecture<a href="computational-security.html#our-first-conjecture" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We are now ready to make our first conjecture:</p>
<blockquote>
<p><strong>The Cipher Conjecture:</strong><a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> There exists a computationally secret encryption
scheme <span class="math inline">\((E,D)\)</span> (where <span class="math inline">\(E,D\)</span> are efficient) with length function <span class="math inline">\(\ell(n)=n+1\)</span>.</p>
</blockquote>
<p>A <em>conjecture</em> is a well defined mathematical statement which (1) we believe is
true but (2) don’t know yet how to prove. Proving the cipher conjecture will be
a great achievement and would in particular settle the P vs NP question, which
is arguably <em>the</em> fundamental question of computer science. That is, the
following theorem is known:</p>
<blockquote>
<h1 id="PNPcipherthm" class="theorem" title="Breaking crypto if P=NP"></h1>
<p>If <span class="math inline">\(P=NP\)</span> then there does not exist a computationally secret
encryption with efficient <span class="math inline">\(E\)</span> and <span class="math inline">\(D\)</span> and where the message is longer than the
key.</p>
</blockquote>
<blockquote>
<h1 id="section-24" class="proof"></h1>
<p>We just sketch the proof, as this is not the focus of this course. If <span class="math inline">\(P=NP\)</span> then whenever we have a loop that searches through
some domain to find some string that satisfies a particular property (like the
loop in the <code>Distinguish</code> subroutine above that searches over all keys) then
this loop can be sped up <em>exponentially</em> .</p>
</blockquote>
<p>While it is very widely believed that <span class="math inline">\(P\neq NP\)</span>, at the moment we do not know
how to <em>prove</em> this, and so have to settle for accepting the cipher conjecture
as essentially an axiom, though we will see later in this course that we can
show it follows from some seemingly weaker conjectures.</p>
<p>There are several reasons to believe the cipher conjecture. We now briefly mention some of them:</p>
<ul>
<li><p><em>Intuition:</em> If the cipher conjecture is false then it means that for <em>every</em> possible cipher we can make the exponential time attack described above become efficient. It seems “too good to be true” in a similar way that the assumption that P=NP seems too good to be true.</p></li>
<li><p><em>Concrete candidates:</em> As we will see in the next lecture, there are several concrete candidate ciphers using keys shorter than messages for which despite <em>tons</em> of effort, no one knows how to break them. Some of them are widely used and hence governments and other benign or not so benign organizations have every reason to invest huge resources in trying to break them. Despite that as far as we know (and we know a little more after Edward Snowden’s revelations) there is no significant break known for the most popular ciphers. Moreover, there are other ciphers that can be based on canonical mathematical problems such as factoring large integers or decoding random linear codes that are immensely interesting in their own right, independently of their cryptographic applications.</p></li>
<li><p><em>Minimalism:</em> Clearly if the cipher conjecture is false then we also don’t have a secure encryption with a message, say, twice as long as the key. But it turns out the cipher conjecture is in fact <em>necessary</em> for essentially every cryptographic primitive, including not just private key and public key encryptions but also digital signatures, hash functions, pseudorandom generators, and more. That is, if the cipher conjecture is false then to a large extent cryptography does not exist, and so we essentially have to assume this conjecture if we want to do any kind of cryptography.</p></li>
</ul>
</div>
<div id="why-care-about-the-cipher-conjecture" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Why care about the cipher conjecture?<a href="computational-security.html#why-care-about-the-cipher-conjecture" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<blockquote>
<p><em>“Give me a place to stand, and I shall move the world”</em> Archimedes, circa
250 BC</p>
</blockquote>
<p>Every perfectly secure encryption scheme is clearly also
computationally secret, and so if we required a message of size <span class="math inline">\(n\)</span> instead
<span class="math inline">\(n+1\)</span>, then the conjecture would have been trivially satisfied by the one-time pad.
However, having a message longer than
the key by just a single bit does not seem that impressive.
Sure, if we used such a scheme with <span class="math inline">\(128\)</span>-bit long keys, our communication will be smaller by a
factor of <span class="math inline">\(128/129\)</span> (or a saving of about <span class="math inline">\(0.8\%\)</span>) over the one-time pad, but
this doesn’t seem worth the risk of using an unproven conjecture.
However, it turns out that if we assume this rather weak condition, we can actually get a
computationally secret encryption scheme with a message of size <span class="math inline">\(p(n)\)</span> for
<em>every</em> polynomial <span class="math inline">\(p(\cdot)\)</span>. In essence, we can fix a single <span class="math inline">\(n\)</span>-bit long key
and communicate securely as many bits as we want!</p>
<p>Moreover, this is just the beginning. There is a huge range of other useful
cryptographic tools that we can obtain from this seemingly innocent conjecture:
(We will see what all these names and some of these reductions mean later in the
course.)</p>
<div class="float" id="tmplabelfig">
<img src="../figure/privatekey-reduction-web.jpg" alt="Web of reductions between notions equivalent to ciphers with larger than key messages" />
<div class="figcaption">Web of reductions between notions equivalent to ciphers with larger than key messages</div>
</div>
<p>We will soon see the first of the many reductions we’ll learn in this course.
Together this “web of reductions” forms the scientific core of cryptography, connecting many of the core concepts and enabling us to construct increasingly sophisticated tools based on relatively simple “axioms” such as the cipher conjecture.</p>
</div>
<div id="prelude-computational-indistinguishability" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Prelude: Computational Indistinguishability<a href="computational-security.html#prelude-computational-indistinguishability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The task of Eve in breaking an encryption scheme is to <em>distinguish</em> between an
encryption of <span class="math inline">\(m_0\)</span> and an encryption of <span class="math inline">\(m_1\)</span>. It turns out to be useful to
consider this question of when two distributions are <em>computationally
indistinguishable</em> more broadly:</p>
<div class="definition" title="Computational Indistinguishability (concrete definition)">
<p><span id="def:compindef" class="definition"><strong>Definition 3.2  </strong></span>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be two
distributions over <span class="math inline">\({\{0,1\}}^m\)</span>. We say that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are
<span class="math inline">\((T,\epsilon)\)</span><em>-computationally indistinguishable</em>, denoted by <span class="math inline">\(X
\approx_{T,\epsilon} Y\)</span>, if for every function <span class="math inline">\(D:\{0,1\}^m \rightarrow \{0,1\}\)</span> computable with at most <span class="math inline">\(T\)</span>
operations,</p>
<p><span class="math display">\[
| \Pr[ D(X) = 1 ] - \Pr[ D(Y) = 1 ] | \leq \epsilon \;.
\]</span></p>
</div>
<div id="compindex" class="solvedexercise" title="Computational Indistinguishability game">
<p>Prove that for every <span class="math inline">\(X,Y\)</span> and <span class="math inline">\(T,\epsilon\)</span> as above <span class="math inline">\(X \approx_{T,\epsilon} Y\)</span> if and only if for every <span class="math inline">\(\leq T\)</span>-operation computable <span class="math inline">\(Eve\)</span>, the probability that <span class="math inline">\(Eve\)</span> wins in the following game is at most <span class="math inline">\(1/2 + \epsilon/2\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>We pick <span class="math inline">\(b \leftarrow_R \{0,1\}\)</span>.</p></li>
<li><p>If <span class="math inline">\(b=0\)</span>, we let <span class="math inline">\(w \leftarrow_R X\)</span>. If <span class="math inline">\(b=1\)</span>, we let <span class="math inline">\(w \leftarrow_R Y\)</span>.</p></li>
<li><p>We give <span class="math inline">\(Eve\)</span> the input <span class="math inline">\(w\)</span>, and <span class="math inline">\(Eve\)</span> outputs <span class="math inline">\(b&#39; \in \{0,1\}\)</span>.</p></li>
<li><p><span class="math inline">\(Eve\)</span> <em>wins</em> if <span class="math inline">\(b=b&#39;\)</span>.</p></li>
</ol>
</div>
<div class="pause">
<p>Working out this exercise on your own is a great way to get comfortable with computational indistinguishability, which is a fundamental notion.</p>
</div>
<div class="solution" data-ref="compindex">
<p><span id="unlabeled-div-8" class="solution"><em>Solution</em>. </span>For every function <span class="math inline">\(Eve:\{0,1\}^m \rightarrow \{0,1\}\)</span>, let <span class="math inline">\(p_X = \Pr[ Eve(X)=1]\)</span> and <span class="math inline">\(p_Y = \Pr[Eve(Y)=1]\)</span>.</p>
<p>Then the probability that <span class="math inline">\(Eve\)</span> wins the game is:</p>
<p><span class="math display">\[\Pr[ b=0](1-p_X) + \Pr[b=1] p_Y\]</span></p>
<p>and since <span class="math inline">\(\Pr[b=0]=\Pr[b=1]=1/2\)</span> this is</p>
<p><span class="math display">\[
\tfrac{1}{2} - \tfrac{1}{2}p_X + \tfrac{1}{2}p_Y = \tfrac{1}{2} + \tfrac{1}{2}(p_Y-p_X)
\]</span></p>
<p>We see that <span class="math inline">\(Eve\)</span> wins the game with success <span class="math inline">\(1/2 + \epsilon/2\)</span> if and only if
<span class="math display">\[
\Pr[ Eve(Y) = 1 ] - \Pr[Eve(X)=1]  = \epsilon \;.
\]</span>
Since <span class="math inline">\(\Pr[ Eve(Y) = 1 ] - \Pr[Eve(X)=1] \leq \left| \Pr[ Eve(X) = 1 ] - \Pr[Eve(Y)=1] \right|\)</span>, this already shows that if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <span class="math inline">\((T,\epsilon)\)</span>-indistinguishable then <span class="math inline">\(Eve\)</span> will win
the game with probability at most <span class="math inline">\(\epsilon/2\)</span>.</p>
<p>For the other direction, assume that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <em>not</em> computationally indistinguishable and let <span class="math inline">\(Eve\)</span> be a <span class="math inline">\(T\)</span> time operation function such that
<span class="math display">\[
\left| \Pr[ Eve(X) = 1 ] - \Pr[Eve(Y)=1]  \right| \geq \epsilon \;.
\]</span></p>
<p>Then by definition of absolute value, there are two options. Either <span class="math inline">\(\Pr[ Eve(X) = 1 ] - \Pr[Eve(Y)=1]  \geq \epsilon\)</span> in which case <span class="math inline">\(Eve\)</span> wins the game with probability at least <span class="math inline">\(1/2 + \epsilon/2\)</span>.
Otherwise <span class="math inline">\(\Pr[ Eve(X) = 1 ] - \Pr[Eve(Y)=1]  \leq -\epsilon\)</span>, in which case the function <span class="math inline">\(Eve&#39;(w)=1-Eve(w)\)</span> (which is just as easy to compute) wins the game with probability at least <span class="math inline">\(1/2 + \epsilon/2\)</span>.</p>
<p>Note that above we assume that the class of “functions computable in at most <span class="math inline">\(T\)</span> operations” is <em>closed under negation</em>, in the sense that if <span class="math inline">\(F\)</span> is in this class, then <span class="math inline">\(1-F\)</span> is also. For standard Boolean circuits, this can be done if we don’t count negation gates (which can change the total circuit size by at most a factor of two), or we can allow for <span class="math inline">\(Eve&#39;\)</span> to require a constant additional number of operations, in which case the exercise is still essentially true but is slightly more cumbersome to state.</p>
</div>
<p>As we did with computational secrecy, we can also define an asymptotic definition of computational indistinguishability.</p>
<div class="definition" title="Computational indistt">
<p><span id="def:compindefasymp" class="definition"><strong>Definition 3.3  </strong></span>Let <span class="math inline">\(m:\N \rightarrow \N\)</span> be some function and let <span class="math inline">\(\{ X_n \}_{n\in \N}\)</span> and <span class="math inline">\(\{ Y_n \}_{n\in \N}\)</span> be two sequences of
distributions such that <span class="math inline">\(X_n\)</span> and <span class="math inline">\(Y_n\)</span> are distributions over <span class="math inline">\(\{0,1\}^{m(n)}\)</span>.</p>
<p>We say that <span class="math inline">\(\{ X_n \}_{n\in \N}\)</span> and <span class="math inline">\(\{ Y_n \}_{n\in\N}\)</span> are <em>computationally indistinguishable</em>, denoted by <span class="math inline">\(\{ X_n \}_{n\in\N} \approx \{ Y_n \}_{n\in\N}\)</span>, if for every polynomial <span class="math inline">\(p:\N \rightarrow \N\)</span> and sufficiently large <span class="math inline">\(n\)</span>,
<span class="math inline">\(X_n \approx_{p(n), 1/p(n)} Y_n\)</span>.</p>
</div>
<p>Solving the following asymptotic analog of <a href="" class="ref">compindex</a> is a good way to get comfortable with the asymptotic definition of computational indistinguishability:</p>
<div class="exercise" title="Computational Indistinguishability game (asymptotic)">
<p><span id="exr:asymgame" class="exercise"><strong>Exercise 3.2  </strong></span>Let <span class="math inline">\(\{ X_n \}_{n\in \N},\{Y_n\}_{n\in \N}\)</span> and <span class="math inline">\(m:\N \rightarrow \N\)</span> be as above. Then <span class="math inline">\(\{ X_n \}_{n\in\N} \approx \{ Y_n \}_{n\in\N}\)</span> if and only if for every polynomial-time <span class="math inline">\(Eve\)</span>, there is some negligible function <span class="math inline">\(\mu\)</span> such that <span class="math inline">\(Eve\)</span> wins the following game with probability at most <span class="math inline">\(1/2 + \mu(n)\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>We pick <span class="math inline">\(b \leftarrow_R \{0,1\}\)</span>.</p></li>
<li><p>If <span class="math inline">\(b=0\)</span>, we let <span class="math inline">\(w \leftarrow_R X_n\)</span>. If <span class="math inline">\(b=1\)</span>, we let <span class="math inline">\(w \leftarrow_R Y_n\)</span>.</p></li>
<li><p>We give <span class="math inline">\(Eve\)</span> the input <span class="math inline">\(w\)</span>, and <span class="math inline">\(Eve\)</span> outputs <span class="math inline">\(b&#39; \in \{0,1\}\)</span>.</p></li>
<li><p><span class="math inline">\(Eve\)</span> <em>wins</em> if <span class="math inline">\(b=b&#39;\)</span>.</p></li>
</ol>
</div>
<p><strong>Dropping the index <span class="math inline">\(n\)</span>.</strong> Since the index <span class="math inline">\(n\)</span> of our distributions would often be clear from context (indeed in most cases it will be the length of the key), we will sometimes drop it from our notation.
So if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are two random variables that depend on some index <span class="math inline">\(n\)</span>, we will say that <span class="math inline">\(X\)</span> is computationally indistinguishable from <span class="math inline">\(Y\)</span> (denoted as <span class="math inline">\(X \approx Y\)</span>) when the sequences <span class="math inline">\(\{ X_n \}_{n\in \N}\)</span> and <span class="math inline">\(\{ Y_n \}_{n\in\N}\)</span> are computationally indistinguishable.</p>
<p>We can use computational indistinguishability to phrase the definition of
computational secrecy more succinctly:</p>
<blockquote>
<h1 id="compindsecthm" class="theorem" title="Computational Indistinguishability phrasing of security"></h1>
<p>Let <span class="math inline">\((E,D)\)</span> be a valid
encryption scheme. Then <span class="math inline">\((E,D)\)</span> is computationally secret if and only if for
every two messages <span class="math inline">\(m_0,m_1 \in \{0,1\}^\ell\)</span>,
<span class="math display">\[ \{ E_k(m_0) \}_{n\in \N}  \approx \{ E_k(m_1) \}_{n\in\N}\]</span>
where each of these two distributions is obtained by sampling a random
<span class="math inline">\(k{\leftarrow_{\tiny R}}{\{0,1\}}^n\)</span>.</p>
</blockquote>
<p>Working out the proof is an excellent way to make sure you understand both the definition of computational secrecy and computational indistinguishability, and hence we leave it as an exercise.</p>
<p>One intuition for computational indistinguishability is that it is related to some
notion of <em>distance</em>.
If two distributions are computationally
indistinguishable, then we can think of them as “very close” to one another, at
least as far as efficient observers are concerned. Intuitively, if <span class="math inline">\(X\)</span> is close
to <span class="math inline">\(Y\)</span> and <span class="math inline">\(Y\)</span> is close to <span class="math inline">\(Z\)</span> then <span class="math inline">\(X\)</span> should be close to <span class="math inline">\(Z\)</span>.<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a> Similarly if
four distributions <span class="math inline">\(X,X&#39;,Y,Y&#39;\)</span> satisfy that <span class="math inline">\(X\)</span> is close to <span class="math inline">\(Y\)</span> and <span class="math inline">\(X&#39;\)</span> is
close to <span class="math inline">\(Y&#39;\)</span>, then you might expect that the distribution <span class="math inline">\((X,X&#39;)\)</span> where we
take two independent samples from <span class="math inline">\(X\)</span> and <span class="math inline">\(X&#39;\)</span> respectively, is close to the
distribution <span class="math inline">\((Y,Y&#39;)\)</span> where we take two independent samples from <span class="math inline">\(Y\)</span> and <span class="math inline">\(Y&#39;\)</span>
respectively.
We will now verify that these intuitions are in fact correct:</p>
<blockquote>
<h1 id="triangleeqthm" class="theorem" title="Triangle Inequality for Computational Indistinguishability"></h1>
<p>Suppose <span class="math inline">\(X_1 \approx_{T,\epsilon} X_2  \approx_{T,\epsilon} \cdots \approx_{T,\epsilon}  X_m\)</span>.
Then <span class="math inline">\(X_1 \approx_{T, (m-1)\epsilon} X_m\)</span>.</p>
</blockquote>
<blockquote>
<h1 id="section-25" class="proof"></h1>
<p>Suppose that there exists a <span class="math inline">\(T\)</span> time <span class="math inline">\(Eve\)</span> such that
<span class="math display">\[
|\Pr[ Eve(X_1)=1] - \Pr[ Eve(X_m)=1]| &gt; (m-1)\epsilon \;.
\]</span></p>
<p>Write
<span class="math display">\[
\Pr[ Eve(X_1)=1] - \Pr[ Eve(X_m)=1] = \sum_{i=1}^{m-1} \left( \Pr[ Eve(X_i)=1] - \Pr[ Eve(X_{i+1})=1] \right)  \;.
\]</span></p>
<p>Thus,
<span class="math display">\[
\sum_{i=1}^{m-1} \left| \Pr[ Eve(X_i)=1] - \Pr[ Eve(X_{i+1})=1] \right| &gt; (m-1)\epsilon
\]</span>
and hence in particular there must exist some <span class="math inline">\(i\in\{1,\ldots,m-1\}\)</span> such that
<span class="math display">\[
\left| \Pr[ Eve(X_i)=1] - \Pr[ Eve(X_{i+1})=1] \right| &gt; \epsilon
\]</span>
contradicting the assumption that <span class="math inline">\(\{ X_i \} \approx_{T,\epsilon} \{ X_{i+1} \}\)</span>
for all <span class="math inline">\(i\in\{1,\ldots,m-1\}\)</span>.</p>
</blockquote>
<blockquote>
<h1 id="compindrepthm" class="theorem" title="Computational Indistinguishability is preserved under repetition"></h1>
<p>Suppose that <span class="math inline">\(X_1,\ldots,X_\ell,Y_1,\ldots,Y_\ell\)</span> are distributions over
<span class="math inline">\({\{0,1\}}^n\)</span> such that <span class="math inline">\(X_i \approx_{T,\epsilon} Y_i\)</span>. Then
<span class="math inline">\((X_1,\ldots,X_\ell) \approx_{T-10\ell n,\ell\epsilon} (Y_1,\ldots,Y_\ell)\)</span>.</p>
</blockquote>
<div class="proof" data-ref="compindrepthm">
<p><span id="unlabeled-div-9" class="proof"><em>Proof</em>. </span>For every <span class="math inline">\(i\in\{0,\ldots,\ell\}\)</span> we define <span class="math inline">\(H_i\)</span> to be the
distribution <span class="math inline">\((X_1,\ldots,X_i,Y_{i+1},\ldots,Y_\ell)\)</span>. Clearly <span class="math inline">\(H_\ell = (X_1,\ldots,X_\ell)\)</span> and <span class="math inline">\(H_0 = (Y_1,\ldots,Y_\ell)\)</span>. We will prove that for
every <span class="math inline">\(i\)</span>, <span class="math inline">\(H_{i-1} \approx_{T-10\ell n,\epsilon} H_i\)</span>, and the proof will then
follow from the triangle inequality (can you see why?). Indeed, suppose towards
the sake of contradiction that there was some <span class="math inline">\(i\in \{1,\ldots,\ell\}\)</span> and some
<span class="math inline">\(T-10\ell n\)</span>-time <span class="math inline">\(Eve&#39;:{\{0,1\}}^{n\ell}\rightarrow{\{0,1\}}\)</span> such that</p>
<p><span class="math display">\[
\left| {\mathbb{E}}[ Eve&#39;(H_{i-1}) ] - {\mathbb{E}}[ Eve&#39;(H_i) ] \right|  &gt; \epsilon\;.
\]</span></p>
<p>In other words
<span class="math display">\[
\left| {\mathbb{E}}_{X_1,\ldots,X_{i-1},Y_i,\ldots,Y_\ell}[ Eve&#39;(X_1,\ldots,X_{i-1},Y_i,\ldots,Y_\ell) ] - {\mathbb{E}}_{X_1,\ldots,X_i,Y_{i+1},\ldots,Y_\ell}[ Eve&#39;(X_1,\ldots,X_i,Y_{i+1},\ldots,Y_\ell) ]   \right|  &gt; \epsilon\;.
\]</span></p>
<p>By linearity of expectation we can write the difference of these two
expectations as
<span class="math display">\[
{\mathbb{E}}_{X_1,\ldots,X_{i-1},X_i,Y_i,Y_{i+1},\ldots,Y_\ell}\left[ Eve&#39;(X_1,\ldots,X_{i-1},Y_i,Y_{i+1},\ldots,Y_\ell) -  Eve&#39;(X_1,\ldots,X_{i-1},X_i,Y_{i+1},\ldots,Y_\ell) \right]
\]</span></p>
<p>By the <em>averaging principle</em><a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a> this means that there exist some values
<span class="math inline">\(x_1,\ldots,x_{i-1},y_{i+1},\ldots,y_\ell\)</span> such that
<span class="math display">\[
\left|{\mathbb{E}}_{X_i,Y_i}\left[ Eve&#39;(x_1,\ldots,x_{i-1},Y_i,y_{i+1},\ldots,y_\ell) -  Eve&#39;(x_1,\ldots,x_{i-1},X_i,y_{i+1},\ldots,y_\ell) \right]\right|&gt;\epsilon
\]</span>
Now <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y_i\)</span> are simply independent draws from the distributions <span class="math inline">\(X\)</span> and
<span class="math inline">\(Y\)</span> respectively, and so if we define <span class="math inline">\(Eve(z) =
Eve&#39;(x_1,\ldots,x_{i-1},z,y_{i+1},\ldots,y_\ell)\)</span> then <span class="math inline">\(Eve\)</span> runs in time at
most the running time of <span class="math inline">\(Eve&#39;\)</span> plus <span class="math inline">\(10\ell n\)</span><a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a> and it satisfies
<span class="math display">\[
\left| {\mathbb{E}}_{X_i} [ Eve(X_i) ] - {\mathbb{E}}_{Y_i} [ Eve(Y_i) ] \right| &gt; \epsilon
\]</span>
contradicting the assumption that <span class="math inline">\(X_i \approx_{T,\epsilon} Y_i\)</span>.</p>
</div>
<blockquote>
<h1 id="hybridrem" class="remark" title="The hybrid argument"></h1>
<p>The above proof illustrates a powerful technique known as the <em>hybrid
argument</em> whereby we show that two distribution <span class="math inline">\(C^0\)</span> and <span class="math inline">\(C^1\)</span> are close to
each other by coming up with a sequence of distributions <span class="math inline">\(H_0,\ldots,H_t\)</span> such
that <span class="math inline">\(H_t = C^1, H_0 = C^0\)</span>, and we can argue that <span class="math inline">\(H_i\)</span> is close to <span class="math inline">\(H_{i+1}\)</span>
for all <span class="math inline">\(i\)</span>. This type of argument repeats itself time and again in
cryptography, and so it is important to get comfortable with it.</p>
</blockquote>
</div>
<div id="the-length-extension-theorem-or-stream-ciphers" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> The Length Extension Theorem or Stream Ciphers<a href="computational-security.html#the-length-extension-theorem-or-stream-ciphers" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We now turn to show the <em>length extension theorem</em>, stating that if we have an encryption for <span class="math inline">\(n+1\)</span>-length messages with <span class="math inline">\(n\)</span>-length keys, then we can obtain an encryption with <span class="math inline">\(p(n)\)</span>-length messages for every polynomial <span class="math inline">\(p(n)\)</span>.
For a warm-up, let’s show the easier fact that we can transform an encryption such as above, into one that has keys of length <span class="math inline">\(tn\)</span> and messages of length <span class="math inline">\(t(n+1)\)</span> for every integer <span class="math inline">\(t\)</span>:</p>
<blockquote>
<h1 id="secrepthm" class="theorem" title="Security of repetition"></h1>
<p>Suppose that <span class="math inline">\((E&#39;,D&#39;)\)</span> is a
computationally secret encryption scheme with <span class="math inline">\(n\)</span> bit keys and <span class="math inline">\(n+1\)</span> bit
messages. Then the scheme <span class="math inline">\((E,D)\)</span> where <span class="math inline">\(E_{k_1,\ldots,k_t}(m_1,\ldots,m_t)= (E&#39;_{k_1}(m_1),\ldots, E&#39;_{k_t}(m_t))\)</span>
and <span class="math inline">\(D_{k_1,\ldots,k_t}(c_1,\ldots,c_t)= (D&#39;_{k_1}(c_1),\ldots, D&#39;_{k_t}(c_t))\)</span> is a computationally secret scheme with
<span class="math inline">\(tn\)</span> bit keys and <span class="math inline">\(t(n+1)\)</span> bit messages.</p>
</blockquote>
<blockquote>
<h1 id="section-26" class="proof"></h1>
<p>This might seem “obvious” but in cryptography, even obvious facts are
sometimes wrong, so it’s important to prove this formally. Luckily, this is a
fairly straightforward implication of the fact that computational
indisinguishability is preserved under many samples. That is, by the security of
<span class="math inline">\((E&#39;,D&#39;)\)</span> we know that for every two messages <span class="math inline">\(m,m&#39; \in {\{0,1\}}^{n+1}\)</span>,
<span class="math inline">\(E&#39;_k(m) \approx E&#39;_k(m&#39;)\)</span> where <span class="math inline">\(k\)</span> is chosen from the distribution <span class="math inline">\(U_n\)</span>.
Therefore by the indistinguishability of many samples lemma, for every two
tuples <span class="math inline">\(m_1,\ldots,m_t \in {\{0,1\}}^{n+1}\)</span> and <span class="math inline">\(m&#39;_1,\ldots,m&#39;_t\in {\{0,1\}}^{n+1}\)</span>,</p>
<p><span class="math display">\[
(E&#39;_{k_1}(m_1),\ldots,E&#39;_{k_t}(m_t)) \approx (E&#39;_{k_1}(m&#39;_1),\ldots,E&#39;_{k_t}(m&#39;_t))
\]</span></p>
<p>for random <span class="math inline">\(k_1,\ldots,k_t\)</span> chosen independently from <span class="math inline">\(U_n\)</span> which is exactly the
condition that <span class="math inline">\((E,D)\)</span> is computationally secret.</p>
</blockquote>
<p><strong>Randomized encryption scheme.</strong> We can now prove the full length extension theorem. Before doing so, we will need to generalize the notion of an encryption scheme to allow a <em>randomized encryption scheme</em>.
That is, we will consider encryption schemes where the encryption algorithm can “toss coins” in its computation.
There is a crucial difference between key material and such “as hoc” (sometimes also known as “ephemeral”) randomness.
Keys need to be not only chosen at random, but also shared in advance between the sender and receiver, and stored securely throughout their lifetime.
The “coin tosses” used by a randomized encryption scheme are generated “on the fly” and are not known to the receiver, nor do they need to be stored long term by the sender.
So, allowing such randomized encryption does not make a difference for most applications of encryption schemes.
In fact, as we will see later in this course, randomized encryption is <em>necessary</em> for security against more sophisticated attacks such as chosen plaintext and chosen ciphertext attacks, as well as for obtaining secure <em>public key</em> encryptions.
We will use the notation <span class="math inline">\(E_k(m;r)\)</span> to denote the output of the encryption algorithm on key <span class="math inline">\(k\)</span>, message <span class="math inline">\(m\)</span> and using internal randomness <span class="math inline">\(r\)</span>.
We often suppress the notation for the randomness, and hence use <span class="math inline">\(E_k(m)\)</span> to denote the random variable obtained by sampling a random <span class="math inline">\(r\)</span> and outputting <span class="math inline">\(E_k(m;r)\)</span>.</p>
<p>We can now show that given an encryption scheme with messages one bit longer than the key, we can obtain a (randomized) encryption scheme with arbitrarily long messages:</p>
<blockquote>
<h1 id="lengthextendthm" class="theorem" title="Length extension of ciphers"></h1>
<p>Suppose that there exists a
computationally secret encryption scheme <span class="math inline">\((E&#39;,D&#39;)\)</span> with key length <span class="math inline">\(n\)</span> and
message length <span class="math inline">\(n+1\)</span>. Then for every polynomial <span class="math inline">\(t(n)\)</span> there exists a (randomized)
computationally secret encryption scheme <span class="math inline">\((E,D)\)</span> with key length <span class="math inline">\(n\)</span> and message
length <span class="math inline">\(t(n)\)</span>.</p>
</blockquote>
<div class="float" id="cipherlengthextensionfig">
<img src="../figure/length-extension.jpg" alt="Constructing a cipher with t bit long messages from one with n+1 long messages" />
<div class="figcaption">Constructing a cipher with <span class="math inline">\(t\)</span> bit long messages from one with <span class="math inline">\(n+1\)</span> long messages</div>
</div>
<div class="pause">
<p>This is perhaps our first example of a non trivial cryptographic theorem, and the blueprint for this proof will be one that we will follow time and again during this course.
Please make sure you read this proof carefully and follow the argument.</p>
</div>
<div class="proof" data-ref="lengthextendthm">
<p><span id="unlabeled-div-10" class="proof"><em>Proof</em>. </span>The construction, depicted in <a href="" class="ref">cipherlengthextensionfig</a>, is actually quite natural and variants of it are used in practice for <em>stream ciphers</em>, which are ways to encrypt arbitrarily long messages using a fixed size key.
The idea is that we use a key <span class="math inline">\(k_0\)</span> of size <span class="math inline">\(n\)</span> to encrypt <strong>(1)</strong> a fresh key <span class="math inline">\(k_1\)</span> of size <span class="math inline">\(n\)</span> and <strong>(2)</strong> one bit of the message. Now we can encrypt <span class="math inline">\(k_2\)</span> using <span class="math inline">\(k_1\)</span> and so on and so forth. We now describe the construction and analysis in detail.</p>
<p>Let <span class="math inline">\(t=t(n)\)</span>. We are given a cipher <span class="math inline">\(E&#39;\)</span> which can encrypt <span class="math inline">\(n+1\)</span>-bit
long messages with an <span class="math inline">\(n\)</span>-bit long key and we need to encrypt a <span class="math inline">\(t\)</span>-bit long
message <span class="math inline">\(m=(m_1,\ldots,m_t) \in {\{0,1\}}^t\)</span>. Our idea is simple (at least in
hindsight). Let <span class="math inline">\(k_0 {\leftarrow_{\tiny R}}{\{0,1\}}^n\)</span> be our key (which is
chosen at random). To encrypt <span class="math inline">\(m\)</span> using <span class="math inline">\(k_0\)</span>, the encryption function will
choose <span class="math inline">\(t\)</span> random strings <span class="math inline">\(k_1,\ldots, k_t {\leftarrow_{\tiny R}}{\{0,1\}}^n\)</span>.
We will then encrypt the <span class="math inline">\(n+1\)</span>-bit long message <span class="math inline">\((k_1,m_1)\)</span>
with the key <span class="math inline">\(k_0\)</span> to obtain the ciphertext <span class="math inline">\(c_1\)</span>, then encrypt the <span class="math inline">\(n+1\)</span>-bit
long message <span class="math inline">\((k_2,m_2)\)</span> with the key <span class="math inline">\(k_1\)</span> to obtain the ciphertext <span class="math inline">\(c_2\)</span>, and
so on and so forth until we encrypt the message <span class="math inline">\((k_t,m_t)\)</span> with the key
<span class="math inline">\(k_{t-1}\)</span>.<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a>
We output <span class="math inline">\((c_1,\ldots,c_t)\)</span> as the final ciphertext.<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a></p>
<p>To decrypt <span class="math inline">\((c_1,\ldots,c_t)\)</span> using the key <span class="math inline">\(k_0\)</span>, first decrypt <span class="math inline">\(c_1\)</span> to learn
<span class="math inline">\((k_1,m_1)\)</span>, then use <span class="math inline">\(k_1\)</span> to decrypt <span class="math inline">\(c_2\)</span> to learn <span class="math inline">\((k_2,m_2)\)</span>, and so on
until we use <span class="math inline">\(k_{t-1}\)</span> to decrypt <span class="math inline">\(c_t\)</span> and learn <span class="math inline">\((k_t,m_t)\)</span>. Finally we can
simply output <span class="math inline">\((m_1,\ldots,m_t)\)</span>.</p>
<p>The above are clearly valid encryption and decryption algorithms, and hence the
real question becomes <em>is it secure??</em>. The intuition is that <span class="math inline">\(c_1\)</span> hides all
information about <span class="math inline">\((k_1,m_1)\)</span> and so in particular the first bit of the message
is encrypted securely, and <span class="math inline">\(k_1\)</span> still can be treated as an unknown random
string even to an adversary that saw <span class="math inline">\(c_1\)</span>. Thus, we can think of <span class="math inline">\(k_1\)</span> as a
random secret key for the encryption <span class="math inline">\(c_2\)</span>, and hence the second bit of the
message is encrypted securely, and so on and so forth.</p>
<p>Our discussion above looks like a reasonable intuitive argument, but to make sure it’s true
we need to give an actual proof. Let <span class="math inline">\(m,m&#39; \in {\{0,1\}}^t\)</span> be two messages. We
need to show that <span class="math inline">\(E_{U_n}(m) \approx E_{U_n}(m&#39;)\)</span>. The heart of the proof will
be the following claim:</p>
<p><strong>Claim:</strong> Let <span class="math inline">\(\hat{E}\)</span> be the algorithm that on input a message <span class="math inline">\(m\)</span> and key
<span class="math inline">\(k_0\)</span> works like <span class="math inline">\(E\)</span> except that its <span class="math inline">\(i^{th}\)</span> block contains
<span class="math inline">\(E&#39;_{k_{i-1}}(k&#39;_i,m_i)\)</span> where <span class="math inline">\(k&#39;_i\)</span> is a <em>random</em> string in <span class="math inline">\({\{0,1\}}^n\)</span>,
that is chosen <em>independently</em> of everything else including the key <span class="math inline">\(k_i\)</span>. Then,
for every message <span class="math inline">\(m\in{\{0,1\}}^t\)</span></p>
<p><span class="math display">\[
E_{U_n}(m) \approx \hat{E}_{U_n}(m)  \label{lengthextendclaimeq} \;.
\]</span></p>
<p>Note that <span class="math inline">\(\hat{E}\)</span> is not a valid encryption scheme since it’s not at all clear
there is a decryption algorithm for it. It is just an hypothetical tool we use
for the proof.
Since both <span class="math inline">\(E\)</span> and <span class="math inline">\(\hat{E}\)</span> are randomized encryption schemes (with <span class="math inline">\(E\)</span> using <span class="math inline">\((t-1)n\)</span> bits of randomness for the ephemeral keys <span class="math inline">\(k_1,\ldots,k_{t-1}\)</span> and <span class="math inline">\(\hat{E}\)</span> using <span class="math inline">\((2t-1)n\)</span> bits of randomness for the ephemeral keys <span class="math inline">\(k_1,\ldots,k_t,k&#39;_2,\ldots,k&#39;_t\)</span>), we can also write
<a href="" class="eqref">lengthextendclaimeq</a> as
<span class="math display">\[
E_{U_n}(m; U&#39;_{tn}) \approx \hat{E}_{U_n}(m; U&#39;_{(2t-1)n})
\]</span>
where we use <span class="math inline">\(U&#39;_\ell\)</span> to denote a random variable that is chosen uniformly at random from <span class="math inline">\(\{0,1\}^\ell\)</span> and independently from the choice of <span class="math inline">\(U_n\)</span> (which is chosen uniformly at random from <span class="math inline">\(\{0,1\}^n\)</span>).</p>
<p>Once we prove the claim then we are done since we know that for
every pair of messages <span class="math inline">\(m,m&#39;\)</span>, <span class="math inline">\(E_{U_n}(m) \approx \hat{E}_{U_n}(m)\)</span> and
<span class="math inline">\(E_{U_n}(m&#39;) \approx \hat{E}_{U_n}(m&#39;)\)</span> but <span class="math inline">\(\hat{E}_{U_n}(m) \approx
\hat{E}_{U_n}(m&#39;)\)</span> since <span class="math inline">\(\hat{E}\)</span> is essentially the same as the <span class="math inline">\(t\)</span>-times
repetition scheme we analyzed above. Thus by the triangle inequality we can
conclude that <span class="math inline">\(E_{U_n}(m) \approx E_{U_n}(m&#39;)\)</span> as we desired.</p>
<p><strong>Proof of claim:</strong> We prove the claim by the hybrid method. For <span class="math inline">\(j\in
\{0,\ldots, t\}\)</span>, let <span class="math inline">\(H_j\)</span> be the distribution of ciphertexts where in the
first <span class="math inline">\(j\)</span> blocks we act like <span class="math inline">\(\hat{E}\)</span> and in the last <span class="math inline">\(t-j\)</span> blocks we act like
<span class="math inline">\(E\)</span>. That is, we choose <span class="math inline">\(k_0,\ldots,k_t,k&#39;_1,\ldots,k&#39;_t\)</span> independently at
random from <span class="math inline">\(U_n\)</span> and the <span class="math inline">\(i^{th}\)</span> block of <span class="math inline">\(H_j\)</span> is equal to
<span class="math inline">\(E&#39;_{k_{i-1}}(k_i,m_i)\)</span> if <span class="math inline">\(i&gt;j\)</span> and is equal to <span class="math inline">\(E&#39;_{k_{i-1}}(k&#39;_i,m_i)\)</span> if
<span class="math inline">\(i\leq j\)</span>. Clearly, <span class="math inline">\(H_t = \hat{E}_{U_n}(m)\)</span> and <span class="math inline">\(H_0 = E_{U_n}(m)\)</span> and so it
suffices to prove that for every <span class="math inline">\(j\)</span>, <span class="math inline">\(H_{j-1} \approx H_j\)</span>. Indeed, let <span class="math inline">\(j \in \{1,\ldots,t\}\)</span>
and suppose towards the sake of contradiction that there
exists an efficient <span class="math inline">\(Eve&#39;\)</span> such that</p>
<p><span class="math display">\[
\left| {\mathbb{E}}[ Eve&#39;(H_{j-1})] - {\mathbb{E}}[ Eve&#39;(H_j)]\right|\geq \epsilon \;\;(*)
\]</span></p>
<p>where <span class="math inline">\(\epsilon = \epsilon(n)\)</span> is noticeable. By the averaging principle, there
exists some fixed choice for
<span class="math inline">\(k&#39;_1,\ldots,k&#39;_t,k_0,\ldots,k_{j-2},k_j,\ldots,k_t\)</span> such that <span class="math inline">\((*)\)</span> still
holds. Note that in this case the only randomness is the choice of
<span class="math inline">\(k_{j-1}{\leftarrow_{\tiny R}}U_n\)</span> and moreover the first <span class="math inline">\(j-1\)</span> blocks and the last
<span class="math inline">\(t-j\)</span> blocks of <span class="math inline">\(H_{j-1}\)</span> and <span class="math inline">\(H_j\)</span> would be identical and we can denote them by
<span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> respectively and hence write <span class="math inline">\((*)\)</span> as</p>
<p><span class="math display">\[
\left| {\mathbb{E}}_{k_{j-1}}[ Eve&#39;(\alpha,E&#39;_{k_{j-1}}(k_j,m_j),\beta) - Eve&#39;(\alpha,E&#39;_{k_{j-1}}(k&#39;_j,m_j),\beta) ] \right| \geq \epsilon \;\;(**)
\]</span></p>
<p>But now consider the adversary <span class="math inline">\(Eve\)</span> that is defined as <span class="math inline">\(Eve(c) =
Eve&#39;(\alpha,c,\beta)\)</span>. Then <span class="math inline">\(Eve\)</span> is also efficient and by <span class="math inline">\((**)\)</span> it can
distinguish between <span class="math inline">\(E&#39;_{U_n}(k_j,m_j)\)</span> and <span class="math inline">\(E&#39;_{U_n}(k&#39;_j,m_j)\)</span> thus
contradicting the security of <span class="math inline">\((E&#39;,D&#39;)\)</span>. This concludes the proof of the claim and hence the theorem.</p>
</div>
<div id="appendix-the-computational-model" class="section level3 hasAnchor" number="3.5.1">
<h3><span class="header-section-number">3.5.1</span> Appendix: The computational model<a href="computational-security.html#appendix-the-computational-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For concreteness sake let us give a precise definition of what it means for a function or probabilistic process <span class="math inline">\(f\)</span> mapping <span class="math inline">\(\{0,1\}^n\)</span> to <span class="math inline">\(\{0,1\}^m\)</span> to be computable using <span class="math inline">\(T\)</span> operations.</p>
<ul>
<li><p>If you have taken any course on computational complexity (such as Harvard CS 121), then this is the model of Boolean circuits, except that we also allow randomization.</p></li>
<li><p>If you have not taken such a course, you might simply take it on faith that it is possible to model what it means for an algorithm to be able to map an input <span class="math inline">\(x\)</span> into an output <span class="math inline">\(f(x)\)</span> using <span class="math inline">\(T\)</span> “elementary operations”.</p></li>
</ul>
<p>In both cases you might want to skip this appendix and only return to it if you find something confusing.</p>
<p>The model we use is a Boolean circuit that also has a <span class="math inline">\(RAND\)</span> gate that outputs a random bit.
We could use as the basic set of gates the standard <span class="math inline">\(AND\)</span>, <span class="math inline">\(OR\)</span> and <span class="math inline">\(NOT\)</span> but for simplicity we use the one-element set <span class="math inline">\(NAND\)</span>.
We represent the circuit as a straightline program, but this is of course just a matter of convenience.
As shown (for example) in the <a href="http://introtcs.org">CS 121 textbook</a>, these two representations are identical.</p>
<div class="definition" title="Probabilistic straightline program">
<p><span id="def:randprogdef" class="definition"><strong>Definition 3.4  </strong></span>A <em>probabilistic straightline program</em> consists of a sequence of lines, each one of them one of the following forms:</p>
<ul>
<li><p><code>foo = NAND(bar, baz)</code> where <code>foo</code>,<code>bar</code>,<code>baz</code> are variable identifiers.</p></li>
<li><p><code>foo = RAND()</code> where <code>foo</code> is a variable identifier.</p></li>
</ul>
</div>
<p>Given a program <span class="math inline">\(\pi\)</span>, we say that its <em>size</em> is the number of lines it contains. Variables of the form <code>X[</code><span class="math inline">\(i\)</span><code>]</code> or <code>Y[</code><span class="math inline">\(j\)</span><code>]</code> are considered input and output variables respectively.
If the input variables range from <span class="math inline">\(0\)</span> to <span class="math inline">\(n-1\)</span> and the output variables range from <span class="math inline">\(0\)</span> to <span class="math inline">\(m-1\)</span> then the program computes the probabilistic process that maps <span class="math inline">\(\{0,1\}^n\)</span> to <span class="math inline">\(\{0,1\}^m\)</span> in the natural way.
If <span class="math inline">\(F\)</span> is a (probabilistic or deterministic) map of <span class="math inline">\(\{0,1\}^n\)</span> to <span class="math inline">\(\{0,1\}^m\)</span>, the <em>complexity</em> of <span class="math inline">\(F\)</span> is the size of the smallest program <span class="math inline">\(P\)</span> that computes it.</p>
<p>If you haven’t taken a class such as CS121 before, you might wonder how such a simple model captures complicated programs that use loops, conditionals, and more complex data types than simply a bit in <span class="math inline">\(\{0,1\}\)</span>, not to mention some special purpose crypto-breaking devices that might involve tailor-made hardware. It turns out that it does (for the same reason we can compile complicated programming languages to run on silicon chips with a very limited instruction set). In fact, as far as we know, this model can capture even computations that happen in nature, whether it’s in a bee colony or the human brain (which contains about <span class="math inline">\(10^{10}\)</span> neurons, so should in principle be simulatable by a program that has up to a few order of magnitudes of the same number of lines). Crucially, for cryptography, we care about such programs not because we want to actually run them, but because we want to argue about their <em>non existence</em>. If we have a process that cannot be computed by a straightline program of length shorter than <span class="math inline">\(2^{128}&gt;10^{38}\)</span> then it seems safe to say that a computer the size of the human brain (or even all the human and nonhuman brains on this planet) will not be able to perform it either.</p>
<p><strong>Advanced note: non uniformity.</strong> The computational model we use in this class is <a href="https://introtcs.org/public/lec_11_running_time.html#nonuniformcompsec"><em>non uniform</em></a> (corresponding to Boolean circuits) as opposed to <em>uniform</em> (corresponding to Turing machines). If this distinction doesn’t mean anything to you, you can ignore it as it won’t play a significant role in what we do next. It basically means that we do allow our programs to have hardwired constants of <span class="math inline">\(poly(n)\)</span> bits where <span class="math inline">\(n\)</span> is the input/key length. In fact, to be precise, we will hold ourselves to a higher standard than our adversary, in the sense that we require our algorithms to be efficient in the stronger sense of being computable in uniform probabilistic polynomial time (for some fixed polynomial, often <span class="math inline">\(O(n)\)</span> or <span class="math inline">\(O(n^2\)</span>)), while the adversary is allowed to use non uniformity.</p>
<p><strong>Quantum computing.</strong> An interesting potential exception to this principle that every natural process should be simulatable by a straightline program of comparable complexity are processes where the quantum mechanical notions of <em>interference</em> and <em>entanglement</em> play a significant role. We will talk about this notion of <em>quantum computing</em> towards the end of the course, though note that much of what we say does not really change when we add quantum into the picture. As discussed in <a href="https://introtcs.org/public/lec_26_quantum_computing.html">the CS 121 text</a>, we can still capture these processes by straightline programs (that now have somewhat more complex form), and so most of what we’ll do just carries over in the same way to the quantum realm as long as we are fine with conjecturing the strong form of the cipher conjecture, namely that the cipher is infeasible to break even for quantum computers. All current evidence points toward this strong form being true as well. The field of constructing encryption schemes that are potentially secure against quantum computers is known as <a href="https://en.wikipedia.org/wiki/Post-quantum_cryptography">post quantum cryptography</a> and we will return to this later in the course.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="14">
<li id="fn14"><p>Another version of “<span class="math inline">\(t\)</span> bits of security” is that a scheme has <span class="math inline">\(t\)</span> bits of security if for every <span class="math inline">\(t_1+t_2 \leq t\)</span>, an attacker running in <span class="math inline">\(2^{t_1}\)</span> time can’t get success probability advantage more than <span class="math inline">\(2^{-t_2}\)</span>. However these two definitions only differ from one another by at most a factor of two. This may be important for practical applications (where the difference between <span class="math inline">\(64\)</span> and <span class="math inline">\(32\)</span> bits of security could be crucial) but won’t matter for our concerns.<a href="computational-security.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>The latter property is known as “semantic security”, see also section 3.2.2 of Katz Lindell on “semantic security” and Section 2 of Boneh-Shoup “computational ciphers and semantic security”.<a href="computational-security.html#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>Some texts reserve the term <em>exponential</em> to functions of the form <span class="math inline">\(2^{\epsilon n}\)</span> for some <span class="math inline">\(\epsilon &gt; 0\)</span> and call a function such as, say, <span class="math inline">\(2^{\sqrt{n}}\)</span> <em>subexponential</em> . However, we will generally not make this distinction in this course.<a href="computational-security.html#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>Negligible functions are sometimes defined with image equalling <span class="math inline">\([0,1]\)</span> as opposed to the set <span class="math inline">\([0,\infty)\)</span> of non-negative real numbers, since they are typically used to bound probabilities. However, this does not make much difference since if <span class="math inline">\(\mu\)</span> is negligible then for large enough <span class="math inline">\(n\)</span>, <span class="math inline">\(\mu(n)\)</span> will be smaller than one.<a href="computational-security.html#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>Note that there is a subtle issue here with the order of quantifiers. For a scheme to be efficient, the algorithms such as encryption and decryption need to run in some <em>fixed</em> polynomial time such as <span class="math inline">\(n^2\)</span> or <span class="math inline">\(n^3\)</span>. In contrast we allow the adversary to run in <em>any</em> polynomial time. That is, for every <span class="math inline">\(c\)</span>, if <span class="math inline">\(n\)</span> is large enough, then the scheme should be secure against an adversary that runs in time <span class="math inline">\(n^c\)</span>. This is in line with the general principle in cryptography that we always allow the adversary potentially much more resources than those used by the honest users. In practical security we often assume that the gap between the honest use and the adversary resources can be <em>exponential</em>. For example, a low power embedded device can encrypt messages that, as far as we know, are undecipherable even by a nation-state using super-computers and massive data centers.<a href="computational-security.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>With some caveats that need to be added due to <em>quantum computers</em>: we’ll get to those later in the course, though they won’t change most of our theory. See also <a href="https://introtcs.org/public/lec_04_code_and_data.html#PECTTsec">this discussion in my intro TCS textbook</a> and <a href="https://www.scottaaronson.com/talks/bernays2.ppt">this presentation of Aaronson</a> on the “extended Church Turing thesis”. <a href="computational-security.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>As will be the case for other conjectures we talk about, the name “The
Cipher Conjecture” is not a standard name, but rather one we’ll use in this
course. In the literature this conjecture is mostly referred to as the
conjecture of existence of <em>one way functions</em>, a notion we will learn about
later. These two conjectures a priori seem quite different but have been shown
to be equivalent.<a href="computational-security.html#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>Results of this form are known as “triangle inequalities” since they can
be viewed as generalizations of the statement that for every three points on the
plane <span class="math inline">\(x,y,z\)</span>, the distance from <span class="math inline">\(x\)</span> to <span class="math inline">\(z\)</span> is not larger than the distance from
<span class="math inline">\(x\)</span> to <span class="math inline">\(y\)</span> plus the distance from <span class="math inline">\(y\)</span> to <span class="math inline">\(z\)</span>. In other words, the edge
<span class="math inline">\(\overline{x,z}\)</span> of the triangle <span class="math inline">\((x,y,z)\)</span> is not longer than the sum of the
lengths of the other two edges <span class="math inline">\(\overline{x,y}\)</span> and <span class="math inline">\(\overline{y,z}\)</span>.<a href="computational-security.html#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p>This is the principle that if the average grade in an exam was at least
<span class="math inline">\(\alpha\)</span> then <em>someone</em> must have gotten at least <span class="math inline">\(\alpha\)</span>, or in other words
that if a real-valued random variable <span class="math inline">\(Z\)</span> satisfies <span class="math inline">\({\mathbb{E}}[Z] \geq \alpha\)</span>
then <span class="math inline">\(\Pr[Z\geq \alpha]&gt;0\)</span>.<a href="computational-security.html#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>The cost <span class="math inline">\(10 \ell n\)</span> is for the operations of feeding the “hardwired” strings <span class="math inline">\(x_1,\ldots,x_{i-1}\)</span>, <span class="math inline">\(y_{i+1},\ldots,y_\ell\)</span> into <span class="math inline">\(Eve&#39;\)</span>. These take up at most <span class="math inline">\(\ell n\)</span> bits, and depending on the computational model, storing and feeding them into <span class="math inline">\(Eve&#39;\)</span> may take <span class="math inline">\(c\ell n\)</span> steps for some small constant <span class="math inline">\(c&lt;10\)</span>. In the future, we will usually ignore such minor details and simply say that if <span class="math inline">\(Eve&#39;\)</span> runs in polynomial time then so will <span class="math inline">\(Eve\)</span>.<a href="computational-security.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>The keys <span class="math inline">\(k_1,\ldots,k_t\)</span> are sometimes known as <em>ephemeral keys</em> in the crypto literature, since they are created only for the purposes of this particular interaction.<a href="computational-security.html#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p>The astute reader might note that the key <span class="math inline">\(k_t\)</span> is actually not used
anywhere in the encryption nor decryption and hence we could encrypt <span class="math inline">\(n\)</span> more
bits of the message instead in this final round. We used the current description
for the sake of symmetry and simplicity of exposition.<a href="computational-security.html#fnref25" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pseudorandomness.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-Computational-security.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
